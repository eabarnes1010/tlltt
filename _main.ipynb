{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f6a48b-bab3-4333-abf3-07711e94b616",
   "metadata": {},
   "source": [
    "# This Looks Like That There\n",
    "\n",
    "Main training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36bf3dd4-d4af-4c8c-89f6-67097628c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import imp #imp.reload(module)\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from icecream import ic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import network\n",
    "import experiment_settings \n",
    "import data_functions\n",
    "import push_prototypes\n",
    "import plots\n",
    "import common_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e0dba3-9a8a-4d45-b00b-7aaface5fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Elizabeth A. Barnes and Randal J Barnes\"\n",
    "__version__ = \"24 November 2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18825d5a-a951-4a29-8dbd-1b1956974b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.facecolor'] = 'white'\n",
    "mpl.rcParams['figure.dpi']= 150\n",
    "dpiFig = 300."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce58c40-dd37-43ea-9ad3-6d6b56b7d166",
   "metadata": {},
   "source": [
    "## Print the detailed system info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e923341-795f-428a-b5bf-d8cafdce1bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version = 3.9.4 (default, Apr  9 2021, 09:32:38) \n",
      "[Clang 10.0.0 ]\n",
      "numpy version = 1.20.1\n",
      "tensorflow version = 2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"python version = {sys.version}\")\n",
    "print(f\"numpy version = {np.__version__}\")\n",
    "print(f\"tensorflow version = {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b515327-ece1-478c-9c99-0d3979739cbe",
   "metadata": {},
   "source": [
    "## Define experiment settings and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0db315d0-951f-4fe1-88b7-168343dfe3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = 'quadrants'#'mjo'\n",
    "\n",
    "imp.reload(experiment_settings)\n",
    "settings = experiment_settings.get_settings(EXP_NAME)\n",
    "\n",
    "imp.reload(common_functions)\n",
    "model_dir, model_diagnostics_dir, vizualization_dir = common_functions.get_exp_directories(EXP_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c333c24-ae7d-43d3-bc87-09fc8e7d8e89",
   "metadata": {},
   "source": [
    "## Define the network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3005d411-649b-484a-8c3e-fc23500e11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED          = settings['random_seed']\n",
    "BATCH_SIZE_PREDICT   = settings['batch_size_predict']\n",
    "BATCH_SIZE           = settings['batch_size']\n",
    "NLAYERS              = settings['nlayers']\n",
    "NFILTERS             = settings['nfilters']   \n",
    "assert(len(NFILTERS)==NLAYERS)\n",
    "\n",
    "NCLASSES             = settings['nclasses']\n",
    "PROTOTYPES_PER_CLASS = settings['prototypes_per_class']\n",
    "NPROTOTYPES          = np.sum(PROTOTYPES_PER_CLASS)\n",
    "\n",
    "NEPOCHS              = settings['nepochs']\n",
    "LR_INIT              = settings['lr']\n",
    "LR_CALLBACK_EPOCH    = settings['lr_cb_epoch']\n",
    "PATIENCE             = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ab2e28-c92f-4c2d-a5d2-96dcfd9625a3",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb857807-8efc-485b-8be6-29751f6a4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521a7140-1796-429f-ad34-1ff25ecca436",
   "metadata": {},
   "source": [
    "## Get and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f94434b-18eb-408a-8810-af9f27cdf522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./data/data_quadrants.mat\n",
      "shuffling the data before train/validation/test split.\n",
      "raw_data        = (9000, 100, 100, 1)\n",
      "training data   = (7200, 100, 100, 1), (7200,)\n",
      "validation data = (1800, 100, 100, 1), (1800,)\n",
      "test data       = (0, 100, 100, 1), (0,)\n",
      "X_mean          = -0.00016575411048148377\n",
      "X_std           = 0.11273003191226523\n"
     ]
    }
   ],
   "source": [
    "imp.reload(data_functions)\n",
    "DATA_NAME = settings['data_name']\n",
    "DATA_DIR = settings['data_dir']\n",
    "\n",
    "if(EXP_NAME[:3]=='mjo'):\n",
    "\n",
    "    labels, data, lat, lon, time = data_functions.load_mjo_data(DATA_DIR)\n",
    "    X_train, y_train, time_train, X_val, y_val, time_val, X_test, y_test, time_test = data_functions.get_and_process_mjo_data(labels,\n",
    "                                                                                         data,\n",
    "                                                                                         time,\n",
    "                                                                                         rng, \n",
    "                                                                                         colored=settings['colored'],\n",
    "                                                                                         standardize=settings['standardize'],\n",
    "                                                                                         shuffle=settings['shuffle'],\n",
    "                                                                                        )        \n",
    "elif(EXP_NAME[:9]=='quadrants'):\n",
    "    filename = DATA_DIR + DATA_NAME + '.mat'\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, lat, lon = data_functions.get_and_process_data(filename, \n",
    "                                                                                        rng, \n",
    "                                                                                        colored=settings['colored'],\n",
    "                                                                                        standardize=settings['standardize'],\n",
    "                                                                                        shuffle=settings['shuffle'],\n",
    "                                                                                        )      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b621855-61ee-4e16-9948-9f2bcf61721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_class_mask = network.createClassIdentity(PROTOTYPES_PER_CLASS)\n",
    "\n",
    "prototypes_of_correct_class_train = np.zeros((len(y_train),NPROTOTYPES))\n",
    "for i in range(0,prototypes_of_correct_class_train.shape[0]):\n",
    "    prototypes_of_correct_class_train[i,:] = proto_class_mask[:,int(y_train[i])]\n",
    "    \n",
    "prototypes_of_correct_class_val   = np.zeros((len(y_val),NPROTOTYPES))    \n",
    "for i in range(0,prototypes_of_correct_class_val.shape[0]):\n",
    "    prototypes_of_correct_class_val[i,:] = proto_class_mask[:,int(y_val[i])]\n",
    "\n",
    "prototypes_of_correct_class_test   = np.zeros((len(y_test),NPROTOTYPES))    \n",
    "for i in range(0,prototypes_of_correct_class_test.shape[0]):\n",
    "    prototypes_of_correct_class_test[i,:] = proto_class_mask[:,int(y_test[i])]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2b2787-9d90-4955-90a4-1a6526c918e9",
   "metadata": {},
   "source": [
    "## Define the training callbacks and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64ca24eb-ab9c-4db0-82c8-94980521c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < LR_CALLBACK_EPOCH:\n",
    "        return np.round(lr,8)\n",
    "    else:\n",
    "        if(epoch % 2 == 0):\n",
    "            return lr/2.\n",
    "        else:\n",
    "            return lr\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)    \n",
    "    \n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_sparse_categorical_accuracy', \n",
    "    mode='max',\n",
    "    patience=settings['patience'], \n",
    "    restore_best_weights=True, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks_list = [\n",
    "#     lr_callback,\n",
    "#     es_callback,\n",
    "]            \n",
    "\n",
    "# metrics\n",
    "metrics_list = [\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa63e6-adc0-40b0-92a1-16dd4cc806f6",
   "metadata": {},
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c87cc2fb-5cf9-4029-824c-c24262ccb729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[32, 32]\n",
      "(100, 100, 1)\n",
      "3\n",
      "[5, 5, 5]\n",
      "88\n",
      "False\n",
      "0.17197201619672103\n",
      "-0.017197201619672104\n",
      "0.5\n",
      "-0.5\n",
      "False\n",
      "8\n",
      "128\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "False\n",
      "Model: \"full_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, 100, 100, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv2D)                 (None, 100, 100, 32) 320         inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 100, 100, 32) 0           conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxpooling_0 (AveragePooling2D) (None, 50, 50, 32)   0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 50, 50, 32)   9248        maxpooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50, 50, 32)   0           conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxpooling_1 (AveragePooling2D) (None, 25, 25, 32)   0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "first_1x1_conv (Conv2D)         (None, 25, 25, 128)  4224        maxpooling_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "second_1x1_conv (Conv2D)        (None, 25, 25, 128)  16512       first_1x1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "prototypes_of_correct_class (In [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prototype (Prototype)           (None, 15)           11295       second_1x1_conv[0][0]            \n",
      "                                                                 prototypes_of_correct_class[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "final_weights (FinalWeights)    (None, 3)            45          prototype[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax_output (Softmax)        (None, 3)            0           final_weights[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 41,644\n",
      "Trainable params: 41,644\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "__ = imp.reload(network)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = network.build_model(\n",
    "    nlayers              = NLAYERS,\n",
    "    nfilters             = NFILTERS,\n",
    "    input_shape          = X_train.shape[1:],\n",
    "    output_shape         = NCLASSES,\n",
    "    prototypes_per_class = PROTOTYPES_PER_CLASS,\n",
    "    network_seed         = RANDOM_SEED,    \n",
    "    prototype_channels   = settings['prototype_channels'],    \n",
    "    coeff_cluster        = settings['coeff_cluster'],\n",
    "    coeff_separation     = settings['coeff_separation'],\n",
    "    coeff_l1             = settings['coeff_l1'],\n",
    "    incorrect_strength   = settings['incorrect_strength'],\n",
    "    double_conv          = settings['double_conv'],\n",
    "    kernel_l1_coeff      = 0.0,#settings['kernel_l1_coeff'],\n",
    "    kernel_l2_coeff      = 0.0,#settings['kernel_l2_coeff'],\n",
    "    drop_rate            = 0.0,\n",
    "    drop_rate_final      = 0.0,        \n",
    "    \n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404175a3-bc7c-4f2e-8445-3985983c8458",
   "metadata": {},
   "source": [
    "## Load pre-trained weights into convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8dbbe1c-cf25-489c-898a-905a537609af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained convolutional layers from ./saved_models/quadrants/pretrained_model_quadrants\n",
      "   loading pretrained weights for --> conv_0\n",
      "   loading pretrained weights for --> conv_1\n"
     ]
    }
   ],
   "source": [
    "if(settings['pretrain'] == True):\n",
    "\n",
    "    if(settings['pretrain_exp'] is None):\n",
    "        PRETRAINED_MODEL = model_dir + 'pretrained_model_' + EXP_NAME \n",
    "    else:\n",
    "        PRETRAINED_MODEL = './saved_models/' + settings['pretrain_exp'] \n",
    "\n",
    "    print('loading pretrained convolutional layers from ' + PRETRAINED_MODEL)\n",
    "    pretrained_model = tf.keras.models.load_model(PRETRAINED_MODEL)\n",
    "\n",
    "    for layer in range(1,len(model.layers)):\n",
    "        if(model.layers[layer].name[:4]=='conv'):\n",
    "            print('   loading pretrained weights for --> ' + model.layers[layer].name)\n",
    "            model.layers[layer].set_weights(pretrained_model.layers[layer].get_weights())\n",
    "else:\n",
    "    print('no pretrained model specified. keeping random initialized weights.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1e13996-3403-43f2-9544-173155b4ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise ValueError('here')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea5c00a-658f-4597-a2fe-57e838c1db8d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b26f9-6628-4c46-b1d3-dda086aa468f",
   "metadata": {},
   "source": [
    "# Run Training Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ab06f5d-7264-4ec3-ba4b-b29712e442e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(network)\n",
    "imp.reload(plots)\n",
    "imp.reload(push_prototypes)\n",
    "imp.reload(experiment_settings)\n",
    "settings = experiment_settings.get_settings(EXP_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e32234e-5283-48e5-8024-d1fd279e80b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.shape(X_train): (7200, 100, 100, 1)\n",
      "ic| np.shape(prototypes_of_correct_class_train): (7200, 15)\n",
      "ic| np.shape(prototypes_of_correct_class_train): (7200, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7200, 15)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(np.shape(X_train))\n",
    "ic(np.shape(prototypes_of_correct_class_train))\n",
    "ic(np.shape(prototypes_of_correct_class_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "933b03cd-4810-4c70-b8fa-3fb05caa3e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): 0.0\n",
      "    np.max(model.layers[-3].get_weights()[1]): 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 0\n",
      "--------------------\n",
      "   conv_0 --> False\n",
      "   maxpooling_0 --> False\n",
      "   conv_1 --> False\n",
      "   maxpooling_1 --> False\n",
      "   first_1x1_conv --> True\n",
      "   second_1x1_conv --> True\n",
      "   prototype --> True\n",
      "   final_weights --> False\n",
      "learning rate = 0.01\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 24s 102ms/step - loss: 8.6444 - sparse_categorical_accuracy: 0.5819 - cluster_cost: 1.8234 - separation_cost: 1.6761 - l1_weights_cost: 7.5000 - val_loss: 8.1004 - val_sparse_categorical_accuracy: 0.7456 - val_cluster_cost: 0.4206 - val_separation_cost: 0.4613 - val_l1_weights_cost: 7.5000\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 22s 97ms/step - loss: 7.8084 - sparse_categorical_accuracy: 0.8993 - cluster_cost: 0.2414 - separation_cost: 0.3008 - l1_weights_cost: 7.5000 - val_loss: 7.7118 - val_sparse_categorical_accuracy: 0.9356 - val_cluster_cost: 0.2010 - val_separation_cost: 0.2278 - val_l1_weights_cost: 7.5000\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 23s 102ms/step - loss: 7.6751 - sparse_categorical_accuracy: 0.9483 - cluster_cost: 0.1544 - separation_cost: 0.1891 - l1_weights_cost: 7.5000 - val_loss: 7.6802 - val_sparse_categorical_accuracy: 0.9472 - val_cluster_cost: 0.1443 - val_separation_cost: 0.1904 - val_l1_weights_cost: 7.5000\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 24s 106ms/step - loss: 7.6597 - sparse_categorical_accuracy: 0.9538 - cluster_cost: 0.1456 - separation_cost: 0.1889 - l1_weights_cost: 7.5000 - val_loss: 7.6312 - val_sparse_categorical_accuracy: 0.9617 - val_cluster_cost: 0.1541 - val_separation_cost: 0.1899 - val_l1_weights_cost: 7.5000\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 22s 99ms/step - loss: 7.6459 - sparse_categorical_accuracy: 0.9600 - cluster_cost: 0.1468 - separation_cost: 0.1901 - l1_weights_cost: 7.5000 - val_loss: 7.6594 - val_sparse_categorical_accuracy: 0.9594 - val_cluster_cost: 0.1378 - val_separation_cost: 0.1843 - val_l1_weights_cost: 7.5000\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 24s 107ms/step - loss: 7.6465 - sparse_categorical_accuracy: 0.9572 - cluster_cost: 0.1417 - separation_cost: 0.1950 - l1_weights_cost: 7.5000 - val_loss: 7.6495 - val_sparse_categorical_accuracy: 0.9594 - val_cluster_cost: 0.1450 - val_separation_cost: 0.2025 - val_l1_weights_cost: 7.5000\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 25s 109ms/step - loss: 7.6310 - sparse_categorical_accuracy: 0.9611 - cluster_cost: 0.1383 - separation_cost: 0.1973 - l1_weights_cost: 7.5000 - val_loss: 7.6253 - val_sparse_categorical_accuracy: 0.9667 - val_cluster_cost: 0.1374 - val_separation_cost: 0.1878 - val_l1_weights_cost: 7.5000\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 29s 127ms/step - loss: 7.6350 - sparse_categorical_accuracy: 0.9615 - cluster_cost: 0.1377 - separation_cost: 0.1929 - l1_weights_cost: 7.5000 - val_loss: 7.6266 - val_sparse_categorical_accuracy: 0.9644 - val_cluster_cost: 0.1372 - val_separation_cost: 0.1925 - val_l1_weights_cost: 7.5000\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 32s 142ms/step - loss: 7.6226 - sparse_categorical_accuracy: 0.9647 - cluster_cost: 0.1304 - separation_cost: 0.1899 - l1_weights_cost: 7.5000 - val_loss: 7.6502 - val_sparse_categorical_accuracy: 0.9517 - val_cluster_cost: 0.1363 - val_separation_cost: 0.1896 - val_l1_weights_cost: 7.5000\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 35s 155ms/step - loss: 7.6174 - sparse_categorical_accuracy: 0.9688 - cluster_cost: 0.1261 - separation_cost: 0.1792 - l1_weights_cost: 7.5000 - val_loss: 7.6398 - val_sparse_categorical_accuracy: 0.9650 - val_cluster_cost: 0.1310 - val_separation_cost: 0.1810 - val_l1_weights_cost: 7.5000\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/quadrants/model_quadrants_stage0\n",
      "INFO:tensorflow:Assets written to: ./saved_models/quadrants/model_quadrants_stage0/assets\n",
      "--------------------\n",
      "TRAINING STAGE = 1\n",
      "--------------------\n",
      "Running Prototype Push\n",
      "8/8 [==============================] - 17s 2s/step\n",
      "Performing push of prototypes.\n",
      "Push complete.\n",
      "\n",
      "   conv_0 --> False\n",
      "   maxpooling_0 --> False\n",
      "   conv_1 --> False\n",
      "   maxpooling_1 --> False\n",
      "   first_1x1_conv --> False\n",
      "   second_1x1_conv --> False\n",
      "   prototype --> False\n",
      "   final_weights --> True\n",
      "learning rate = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -0.77609557\n",
      "    np.max(model.layers[-3].get_weights()[1]): 2.7403998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 15s 62ms/step - loss: 3.1572 - sparse_categorical_accuracy: 0.8827 - cluster_cost: 0.0026 - separation_cost: 8.1787e-05 - l1_weights_cost: 1.8310 - val_loss: 0.7290 - val_sparse_categorical_accuracy: 0.8861 - val_cluster_cost: 0.0025 - val_separation_cost: 7.0672e-05 - val_l1_weights_cost: 0.0723\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 14s 61ms/step - loss: 0.6271 - sparse_categorical_accuracy: 0.8885 - cluster_cost: 0.0026 - separation_cost: 8.1787e-05 - l1_weights_cost: 0.0531 - val_loss: 0.4811 - val_sparse_categorical_accuracy: 0.9078 - val_cluster_cost: 0.0025 - val_separation_cost: 7.0672e-05 - val_l1_weights_cost: 0.0390\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 15s 65ms/step - loss: 0.4462 - sparse_categorical_accuracy: 0.9046 - cluster_cost: 0.0026 - separation_cost: 8.1787e-05 - l1_weights_cost: 0.0473 - val_loss: 0.4391 - val_sparse_categorical_accuracy: 0.9172 - val_cluster_cost: 0.0025 - val_separation_cost: 7.0672e-05 - val_l1_weights_cost: 0.0849\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.3918 - sparse_categorical_accuracy: 0.9076 - cluster_cost: 0.0026 - separation_cost: 8.1787e-05 - l1_weights_cost: 0.0538 - val_loss: 0.3781 - val_sparse_categorical_accuracy: 0.9178 - val_cluster_cost: 0.0025 - val_separation_cost: 7.0672e-05 - val_l1_weights_cost: 0.0580\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 14s 61ms/step - loss: 0.3665 - sparse_categorical_accuracy: 0.9050 - cluster_cost: 0.0026 - separation_cost: 8.1787e-05 - l1_weights_cost: 0.0489 - val_loss: 0.4266 - val_sparse_categorical_accuracy: 0.8906 - val_cluster_cost: 0.0025 - val_separation_cost: 7.0672e-05 - val_l1_weights_cost: 0.0560\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 17s 78ms/step - loss: 0.3596 - sparse_categorical_accuracy: 0.9068 - cluster_cost: 0.0026 - separation_cost: 8.1787e-05 - l1_weights_cost: 0.0461 - val_loss: 0.4003 - val_sparse_categorical_accuracy: 0.9078 - val_cluster_cost: 0.0025 - val_separation_cost: 7.0672e-05 - val_l1_weights_cost: 0.0665\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 15s 68ms/step - loss: 0.3533 - sparse_categorical_accuracy: 0.9047 - cluster_cost: 0.0026 - separation_cost: 8.1787e-05 - l1_weights_cost: 0.0486 - val_loss: 0.3375 - val_sparse_categorical_accuracy: 0.9150 - val_cluster_cost: 0.0025 - val_separation_cost: 7.0672e-05 - val_l1_weights_cost: 0.0362\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 15s 66ms/step - loss: 0.3498 - sparse_categorical_accuracy: 0.9049 - cluster_cost: 0.0026 - separation_cost: 8.1787e-05 - l1_weights_cost: 0.0424 - val_loss: 0.3513 - val_sparse_categorical_accuracy: 0.9144 - val_cluster_cost: 0.0025 - val_separation_cost: 7.0672e-05 - val_l1_weights_cost: 0.0506\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.3561 - sparse_categorical_accuracy: 0.9033 - cluster_cost: 0.0026 - separation_cost: 8.1787e-05 - l1_weights_cost: 0.0472 - val_loss: 0.3457 - val_sparse_categorical_accuracy: 0.9189 - val_cluster_cost: 0.0025 - val_separation_cost: 7.0672e-05 - val_l1_weights_cost: 0.0582\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 14s 62ms/step - loss: 0.3540 - sparse_categorical_accuracy: 0.9056 - cluster_cost: 0.0026 - separation_cost: 8.1787e-05 - l1_weights_cost: 0.0491 - val_loss: 0.3707 - val_sparse_categorical_accuracy: 0.9078 - val_cluster_cost: 0.0025 - val_separation_cost: 7.0672e-05 - val_l1_weights_cost: 0.0594\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/quadrants/model_quadrants_stage1\n",
      "INFO:tensorflow:Assets written to: ./saved_models/quadrants/model_quadrants_stage1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -0.77609557\n",
      "    np.max(model.layers[-3].get_weights()[1]): 2.7403998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 2\n",
      "--------------------\n",
      "   conv_0 --> True\n",
      "   maxpooling_0 --> True\n",
      "   conv_1 --> True\n",
      "   maxpooling_1 --> True\n",
      "   first_1x1_conv --> True\n",
      "   second_1x1_conv --> True\n",
      "   prototype --> True\n",
      "   final_weights --> False\n",
      "learning rate = 0.01\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 43s 189ms/step - loss: 0.3249 - sparse_categorical_accuracy: 0.9080 - cluster_cost: 0.0351 - separation_cost: 0.0458 - l1_weights_cost: 0.0594 - val_loss: 0.2997 - val_sparse_categorical_accuracy: 0.9172 - val_cluster_cost: 0.0329 - val_separation_cost: 0.0408 - val_l1_weights_cost: 0.0594\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 41s 183ms/step - loss: 0.2150 - sparse_categorical_accuracy: 0.9492 - cluster_cost: 0.0267 - separation_cost: 0.0360 - l1_weights_cost: 0.0594 - val_loss: 0.2078 - val_sparse_categorical_accuracy: 0.9428 - val_cluster_cost: 0.0248 - val_separation_cost: 0.0394 - val_l1_weights_cost: 0.0594\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 44s 194ms/step - loss: 0.1879 - sparse_categorical_accuracy: 0.9565 - cluster_cost: 0.0280 - separation_cost: 0.0397 - l1_weights_cost: 0.0594 - val_loss: 0.1759 - val_sparse_categorical_accuracy: 0.9617 - val_cluster_cost: 0.0316 - val_separation_cost: 0.0429 - val_l1_weights_cost: 0.0594\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 40s 179ms/step - loss: 0.1839 - sparse_categorical_accuracy: 0.9603 - cluster_cost: 0.0308 - separation_cost: 0.0424 - l1_weights_cost: 0.0594 - val_loss: 0.2000 - val_sparse_categorical_accuracy: 0.9578 - val_cluster_cost: 0.0281 - val_separation_cost: 0.0365 - val_l1_weights_cost: 0.0594\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 40s 176ms/step - loss: 0.1863 - sparse_categorical_accuracy: 0.9596 - cluster_cost: 0.0310 - separation_cost: 0.0374 - l1_weights_cost: 0.0594 - val_loss: 0.2612 - val_sparse_categorical_accuracy: 0.9172 - val_cluster_cost: 0.0223 - val_separation_cost: 0.0187 - val_l1_weights_cost: 0.0594\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 38s 171ms/step - loss: 0.1721 - sparse_categorical_accuracy: 0.9639 - cluster_cost: 0.0293 - separation_cost: 0.0387 - l1_weights_cost: 0.0594 - val_loss: 0.1872 - val_sparse_categorical_accuracy: 0.9628 - val_cluster_cost: 0.0281 - val_separation_cost: 0.0386 - val_l1_weights_cost: 0.0594\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 41s 180ms/step - loss: 0.1628 - sparse_categorical_accuracy: 0.9660 - cluster_cost: 0.0330 - separation_cost: 0.0449 - l1_weights_cost: 0.0594 - val_loss: 0.1699 - val_sparse_categorical_accuracy: 0.9661 - val_cluster_cost: 0.0429 - val_separation_cost: 0.0486 - val_l1_weights_cost: 0.0594\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 45s 200ms/step - loss: 0.1767 - sparse_categorical_accuracy: 0.9618 - cluster_cost: 0.0360 - separation_cost: 0.0433 - l1_weights_cost: 0.0594 - val_loss: 0.1898 - val_sparse_categorical_accuracy: 0.9567 - val_cluster_cost: 0.0425 - val_separation_cost: 0.0609 - val_l1_weights_cost: 0.0594\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 40s 179ms/step - loss: 0.1666 - sparse_categorical_accuracy: 0.9674 - cluster_cost: 0.0345 - separation_cost: 0.0500 - l1_weights_cost: 0.0594 - val_loss: 0.1775 - val_sparse_categorical_accuracy: 0.9639 - val_cluster_cost: 0.0362 - val_separation_cost: 0.0460 - val_l1_weights_cost: 0.0594\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 39s 175ms/step - loss: 0.1517 - sparse_categorical_accuracy: 0.9714 - cluster_cost: 0.0329 - separation_cost: 0.0464 - l1_weights_cost: 0.0594 - val_loss: 0.1439 - val_sparse_categorical_accuracy: 0.9756 - val_cluster_cost: 0.0346 - val_separation_cost: 0.0463 - val_l1_weights_cost: 0.0594\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/quadrants/model_quadrants_stage2\n",
      "INFO:tensorflow:Assets written to: ./saved_models/quadrants/model_quadrants_stage2/assets\n",
      "--------------------\n",
      "TRAINING STAGE = 3\n",
      "--------------------\n",
      "Running Prototype Push\n",
      "8/8 [==============================] - 9s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -1.3883832\n",
      "    np.max(model.layers[-3].get_weights"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing push of prototypes.\n",
      "Push complete.\n",
      "\n",
      "   conv_0 --> False\n",
      "   maxpooling_0 --> False\n",
      "   conv_1 --> False\n",
      "   maxpooling_1 --> False\n",
      "   first_1x1_conv --> False\n",
      "   second_1x1_conv --> False\n",
      "   prototype --> False\n",
      "   final_weights --> True\n",
      "learning rate = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "()[1]): 3.3345256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 14s 62ms/step - loss: 2.3011 - sparse_categorical_accuracy: 0.9434 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.8222 - val_loss: 1.1921 - val_sparse_categorical_accuracy: 0.9417 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.5029\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.9456 - sparse_categorical_accuracy: 0.9411 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.3895 - val_loss: 0.7349 - val_sparse_categorical_accuracy: 0.9400 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.2762\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.7383 - sparse_categorical_accuracy: 0.9371 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.2347 - val_loss: 0.5401 - val_sparse_categorical_accuracy: 0.9522 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1518\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.5071 - sparse_categorical_accuracy: 0.9385 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1418 - val_loss: 0.4220 - val_sparse_categorical_accuracy: 0.9456 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1010\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 13s 58ms/step - loss: 0.4001 - sparse_categorical_accuracy: 0.9411 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1189 - val_loss: 0.3262 - val_sparse_categorical_accuracy: 0.9372 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0945\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 13s 58ms/step - loss: 0.3360 - sparse_categorical_accuracy: 0.9385 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1055 - val_loss: 0.4851 - val_sparse_categorical_accuracy: 0.8950 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0588\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.3722 - sparse_categorical_accuracy: 0.9333 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1196 - val_loss: 0.6762 - val_sparse_categorical_accuracy: 0.8778 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1333\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.3439 - sparse_categorical_accuracy: 0.9392 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1079 - val_loss: 0.2589 - val_sparse_categorical_accuracy: 0.9511 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0882\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 15s 65ms/step - loss: 0.3201 - sparse_categorical_accuracy: 0.9421 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1016 - val_loss: 0.2871 - val_sparse_categorical_accuracy: 0.9411 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0769\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 13s 58ms/step - loss: 0.3883 - sparse_categorical_accuracy: 0.9353 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1320 - val_loss: 0.5021 - val_sparse_categorical_accuracy: 0.9139 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1099\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/quadrants/model_quadrants_stage3\n",
      "INFO:tensorflow:Assets written to: ./saved_models/quadrants/model_quadrants_stage3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -1.3883832\n",
      "    np.max(model.layers[-3].get_weights()[1]): 3.3345256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 4\n",
      "--------------------\n",
      "   conv_0 --> True\n",
      "   maxpooling_0 --> True\n",
      "   conv_1 --> True\n",
      "   maxpooling_1 --> True\n",
      "   first_1x1_conv --> True\n",
      "   second_1x1_conv --> True\n",
      "   prototype --> True\n",
      "   final_weights --> False\n",
      "learning rate = 0.01\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 42s 185ms/step - loss: 0.2953 - sparse_categorical_accuracy: 0.9370 - cluster_cost: 0.0080 - separation_cost: 0.0137 - l1_weights_cost: 0.1099 - val_loss: 0.2361 - val_sparse_categorical_accuracy: 0.9650 - val_cluster_cost: 0.0041 - val_separation_cost: 0.0123 - val_l1_weights_cost: 0.1099\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 40s 179ms/step - loss: 0.2124 - sparse_categorical_accuracy: 0.9697 - cluster_cost: 0.0050 - separation_cost: 0.0136 - l1_weights_cost: 0.1099 - val_loss: 0.1987 - val_sparse_categorical_accuracy: 0.9767 - val_cluster_cost: 0.0064 - val_separation_cost: 0.0229 - val_l1_weights_cost: 0.1099\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 47s 209ms/step - loss: 0.3217 - sparse_categorical_accuracy: 0.9311 - cluster_cost: 0.0159 - separation_cost: 0.0171 - l1_weights_cost: 0.1099 - val_loss: 0.2173 - val_sparse_categorical_accuracy: 0.9744 - val_cluster_cost: 0.0060 - val_separation_cost: 0.0112 - val_l1_weights_cost: 0.1099\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.3255 - sparse_categorical_accuracy: 0.9306 - cluster_cost: 0.0203 - separation_cost: 0.0180 - l1_weights_cost: 0.1099 - val_loss: 0.2094 - val_sparse_categorical_accuracy: 0.9750 - val_cluster_cost: 0.0041 - val_separation_cost: 0.0048 - val_l1_weights_cost: 0.1099\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 42s 186ms/step - loss: 0.2194 - sparse_categorical_accuracy: 0.9661 - cluster_cost: 0.0050 - separation_cost: 0.0064 - l1_weights_cost: 0.1099 - val_loss: 0.2132 - val_sparse_categorical_accuracy: 0.9806 - val_cluster_cost: 0.0048 - val_separation_cost: 0.0069 - val_l1_weights_cost: 0.1099\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 42s 185ms/step - loss: 0.2394 - sparse_categorical_accuracy: 0.9576 - cluster_cost: 0.0066 - separation_cost: 0.0093 - l1_weights_cost: 0.1099 - val_loss: 0.4082 - val_sparse_categorical_accuracy: 0.8622 - val_cluster_cost: 0.0167 - val_separation_cost: 0.0211 - val_l1_weights_cost: 0.1099\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 38s 167ms/step - loss: 0.2401 - sparse_categorical_accuracy: 0.9614 - cluster_cost: 0.0087 - separation_cost: 0.0120 - l1_weights_cost: 0.1099 - val_loss: 0.2266 - val_sparse_categorical_accuracy: 0.9650 - val_cluster_cost: 0.0067 - val_separation_cost: 0.0088 - val_l1_weights_cost: 0.1099\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 39s 175ms/step - loss: 0.2128 - sparse_categorical_accuracy: 0.9676 - cluster_cost: 0.0063 - separation_cost: 0.0104 - l1_weights_cost: 0.1099 - val_loss: 0.4115 - val_sparse_categorical_accuracy: 0.9106 - val_cluster_cost: 0.0081 - val_separation_cost: 0.0111 - val_l1_weights_cost: 0.1099\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 40s 179ms/step - loss: 0.3549 - sparse_categorical_accuracy: 0.9212 - cluster_cost: 0.0065 - separation_cost: 0.0108 - l1_weights_cost: 0.1099 - val_loss: 0.2909 - val_sparse_categorical_accuracy: 0.9472 - val_cluster_cost: 0.0074 - val_separation_cost: 0.0136 - val_l1_weights_cost: 0.1099\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 39s 172ms/step - loss: 0.3863 - sparse_categorical_accuracy: 0.9074 - cluster_cost: 0.0498 - separation_cost: 0.0539 - l1_weights_cost: 0.1099 - val_loss: 0.2573 - val_sparse_categorical_accuracy: 0.9444 - val_cluster_cost: 0.0132 - val_separation_cost: 0.0240 - val_l1_weights_cost: 0.1099\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/quadrants/model_quadrants_stage4\n",
      "INFO:tensorflow:Assets written to: ./saved_models/quadrants/model_quadrants_stage4/assets\n",
      "--------------------\n",
      "TRAINING STAGE = 5\n",
      "--------------------\n",
      "Running Prototype Push\n",
      "8/8 [==============================] - 9s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -2.0996497\n",
      "    np.max(model.layers[-3].get_weights()[1]): 4.885483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing push of prototypes.\n",
      "Push complete.\n",
      "\n",
      "   conv_0 --> False\n",
      "   maxpooling_0 --> False\n",
      "   conv_1 --> False\n",
      "   maxpooling_1 --> False\n",
      "   first_1x1_conv --> False\n",
      "   second_1x1_conv --> False\n",
      "   prototype --> False\n",
      "   final_weights --> True\n",
      "learning rate = 0.01\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 15s 65ms/step - loss: 1.5045 - sparse_categorical_accuracy: 0.9079 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.2969 - val_loss: 1.1889 - val_sparse_categorical_accuracy: 0.9272 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.3034\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 13s 58ms/step - loss: 0.9708 - sparse_categorical_accuracy: 0.9185 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.2104 - val_loss: 0.9706 - val_sparse_categorical_accuracy: 0.9361 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1863\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.7600 - sparse_categorical_accuracy: 0.9289 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1575 - val_loss: 0.7798 - val_sparse_categorical_accuracy: 0.9367 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1182\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 1.0787 - sparse_categorical_accuracy: 0.9132 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1978 - val_loss: 0.7030 - val_sparse_categorical_accuracy: 0.9317 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1357\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.7392 - sparse_categorical_accuracy: 0.9276 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1445 - val_loss: 3.3349 - val_sparse_categorical_accuracy: 0.6056 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.2772\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.9351 - sparse_categorical_accuracy: 0.9181 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1747 - val_loss: 0.8858 - val_sparse_categorical_accuracy: 0.8861 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1137\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.9828 - sparse_categorical_accuracy: 0.9179 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1816 - val_loss: 1.6785 - val_sparse_categorical_accuracy: 0.7272 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1916\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 1.0455 - sparse_categorical_accuracy: 0.9179 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1945 - val_loss: 0.7518 - val_sparse_categorical_accuracy: 0.9328 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1129\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 1.1048 - sparse_categorical_accuracy: 0.9146 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1790 - val_loss: 1.2785 - val_sparse_categorical_accuracy: 0.8933 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0820\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.8657 - sparse_categorical_accuracy: 0.9221 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1497 - val_loss: 1.1590 - val_sparse_categorical_accuracy: 0.9139 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.2873\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/quadrants/model_quadrants_stage5\n",
      "INFO:tensorflow:Assets written to: ./saved_models/quadrants/model_quadrants_stage5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -2.0996497\n",
      "    np.max(model.layers[-3].get_weights()[1]): 4.885483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 6\n",
      "--------------------\n",
      "   conv_0 --> True\n",
      "   maxpooling_0 --> True\n",
      "   conv_1 --> True\n",
      "   maxpooling_1 --> True\n",
      "   first_1x1_conv --> True\n",
      "   second_1x1_conv --> True\n",
      "   prototype --> True\n",
      "   final_weights --> False\n",
      "learning rate = 0.001\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 41s 177ms/step - loss: 0.5679 - sparse_categorical_accuracy: 0.9429 - cluster_cost: 5.5189e-04 - separation_cost: 6.6216e-04 - l1_weights_cost: 0.2873 - val_loss: 0.4959 - val_sparse_categorical_accuracy: 0.9594 - val_cluster_cost: 9.7442e-04 - val_separation_cost: 0.0013 - val_l1_weights_cost: 0.2873\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 39s 174ms/step - loss: 0.4315 - sparse_categorical_accuracy: 0.9622 - cluster_cost: 0.0012 - separation_cost: 0.0020 - l1_weights_cost: 0.2873 - val_loss: 0.4423 - val_sparse_categorical_accuracy: 0.9617 - val_cluster_cost: 0.0016 - val_separation_cost: 0.0026 - val_l1_weights_cost: 0.2873\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 38s 169ms/step - loss: 0.4008 - sparse_categorical_accuracy: 0.9675 - cluster_cost: 0.0019 - separation_cost: 0.0029 - l1_weights_cost: 0.2873 - val_loss: 0.4232 - val_sparse_categorical_accuracy: 0.9650 - val_cluster_cost: 0.0018 - val_separation_cost: 0.0031 - val_l1_weights_cost: 0.2873\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 39s 172ms/step - loss: 0.3919 - sparse_categorical_accuracy: 0.9683 - cluster_cost: 0.0018 - separation_cost: 0.0033 - l1_weights_cost: 0.2873 - val_loss: 0.4070 - val_sparse_categorical_accuracy: 0.9650 - val_cluster_cost: 0.0021 - val_separation_cost: 0.0037 - val_l1_weights_cost: 0.2873\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 40s 176ms/step - loss: 0.3848 - sparse_categorical_accuracy: 0.9694 - cluster_cost: 0.0020 - separation_cost: 0.0038 - l1_weights_cost: 0.2873 - val_loss: 0.3994 - val_sparse_categorical_accuracy: 0.9661 - val_cluster_cost: 0.0025 - val_separation_cost: 0.0044 - val_l1_weights_cost: 0.2873\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 40s 180ms/step - loss: 0.3790 - sparse_categorical_accuracy: 0.9704 - cluster_cost: 0.0022 - separation_cost: 0.0042 - l1_weights_cost: 0.2873 - val_loss: 0.4064 - val_sparse_categorical_accuracy: 0.9644 - val_cluster_cost: 0.0017 - val_separation_cost: 0.0032 - val_l1_weights_cost: 0.2873\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 39s 173ms/step - loss: 0.3760 - sparse_categorical_accuracy: 0.9717 - cluster_cost: 0.0023 - separation_cost: 0.0041 - l1_weights_cost: 0.2873 - val_loss: 0.3896 - val_sparse_categorical_accuracy: 0.9683 - val_cluster_cost: 0.0026 - val_separation_cost: 0.0045 - val_l1_weights_cost: 0.2873\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 40s 177ms/step - loss: 0.3729 - sparse_categorical_accuracy: 0.9715 - cluster_cost: 0.0025 - separation_cost: 0.0042 - l1_weights_cost: 0.2873 - val_loss: 0.3786 - val_sparse_categorical_accuracy: 0.9689 - val_cluster_cost: 0.0023 - val_separation_cost: 0.0037 - val_l1_weights_cost: 0.2873\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 41s 184ms/step - loss: 0.3783 - sparse_categorical_accuracy: 0.9703 - cluster_cost: 0.0023 - separation_cost: 0.0039 - l1_weights_cost: 0.2873 - val_loss: 0.3853 - val_sparse_categorical_accuracy: 0.9683 - val_cluster_cost: 0.0019 - val_separation_cost: 0.0030 - val_l1_weights_cost: 0.2873\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 41s 181ms/step - loss: 0.3969 - sparse_categorical_accuracy: 0.9640 - cluster_cost: 0.0026 - separation_cost: 0.0044 - l1_weights_cost: 0.2873 - val_loss: 0.3931 - val_sparse_categorical_accuracy: 0.9661 - val_cluster_cost: 0.0027 - val_separation_cost: 0.0047 - val_l1_weights_cost: 0.2873\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/quadrants/model_quadrants_stage6\n",
      "INFO:tensorflow:Assets written to: ./saved_models/quadrants/model_quadrants_stage6/assets\n",
      "--------------------\n",
      "TRAINING STAGE = 7\n",
      "--------------------\n",
      "Running Prototype Push\n",
      "8/8 [==============================] - 8s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -2.1521041\n",
      "    np.max(model.layers[-3].get_weights()[1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing push of prototypes.\n",
      "Push complete.\n",
      "\n",
      "   conv_0 --> False\n",
      "   maxpooling_0 --> False\n",
      "   conv_1 --> False\n",
      "   maxpooling_1 --> False\n",
      "   first_1x1_conv --> False\n",
      "   second_1x1_conv --> False\n",
      "   prototype --> False\n",
      "   final_weights --> True\n",
      "learning rate = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "]): 5.0507536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 14s 59ms/step - loss: 0.5137 - sparse_categorical_accuracy: 0.9548 - cluster_cost: 2.6177e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1804 - val_loss: 0.5035 - val_sparse_categorical_accuracy: 0.9411 - val_cluster_cost: 2.6234e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0948\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 13s 58ms/step - loss: 0.3347 - sparse_categorical_accuracy: 0.9513 - cluster_cost: 2.6177e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0620 - val_loss: 0.3996 - val_sparse_categorical_accuracy: 0.9417 - val_cluster_cost: 2.6234e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0527\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.2819 - sparse_categorical_accuracy: 0.9553 - cluster_cost: 2.6177e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0404 - val_loss: 0.3258 - val_sparse_categorical_accuracy: 0.9522 - val_cluster_cost: 2.6234e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0339\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.2655 - sparse_categorical_accuracy: 0.9550 - cluster_cost: 2.6177e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0378 - val_loss: 0.2939 - val_sparse_categorical_accuracy: 0.9511 - val_cluster_cost: 2.6234e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0307\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.2524 - sparse_categorical_accuracy: 0.9553 - cluster_cost: 2.6177e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0348 - val_loss: 0.2738 - val_sparse_categorical_accuracy: 0.9500 - val_cluster_cost: 2.6234e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0273\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.2477 - sparse_categorical_accuracy: 0.9522 - cluster_cost: 2.6177e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0314 - val_loss: 0.2773 - val_sparse_categorical_accuracy: 0.9494 - val_cluster_cost: 2.6234e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0333\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 13s 58ms/step - loss: 0.2285 - sparse_categorical_accuracy: 0.9543 - cluster_cost: 2.6177e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0290 - val_loss: 0.2653 - val_sparse_categorical_accuracy: 0.9489 - val_cluster_cost: 2.6234e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0327\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 14s 61ms/step - loss: 0.2415 - sparse_categorical_accuracy: 0.9497 - cluster_cost: 2.6177e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0319 - val_loss: 0.2697 - val_sparse_categorical_accuracy: 0.9494 - val_cluster_cost: 2.6234e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0327\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.2277 - sparse_categorical_accuracy: 0.9533 - cluster_cost: 2.6177e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0294 - val_loss: 0.2390 - val_sparse_categorical_accuracy: 0.9517 - val_cluster_cost: 2.6234e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0269\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.2293 - sparse_categorical_accuracy: 0.9507 - cluster_cost: 2.6177e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0297 - val_loss: 0.2386 - val_sparse_categorical_accuracy: 0.9539 - val_cluster_cost: 2.6234e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0352\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/quadrants/model_quadrants_stage7\n",
      "INFO:tensorflow:Assets written to: ./saved_models/quadrants/model_quadrants_stage7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -2.1521041\n",
      "    np.max(model.layers[-3].get_weights()[1]): 5.0507536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 8\n",
      "--------------------\n",
      "   conv_0 --> True\n",
      "   maxpooling_0 --> True\n",
      "   conv_1 --> True\n",
      "   maxpooling_1 --> True\n",
      "   first_1x1_conv --> True\n",
      "   second_1x1_conv --> True\n",
      "   prototype --> True\n",
      "   final_weights --> False\n",
      "learning rate = 1e-04\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 39s 171ms/step - loss: 0.1668 - sparse_categorical_accuracy: 0.9608 - cluster_cost: 1.5164e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0352 - val_loss: 0.1953 - val_sparse_categorical_accuracy: 0.9611 - val_cluster_cost: 3.0785e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0352\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 40s 178ms/step - loss: 0.1449 - sparse_categorical_accuracy: 0.9669 - cluster_cost: 4.1545e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0352 - val_loss: 0.1740 - val_sparse_categorical_accuracy: 0.9639 - val_cluster_cost: 6.1035e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0352\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 41s 181ms/step - loss: 0.1343 - sparse_categorical_accuracy: 0.9696 - cluster_cost: 6.8183e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0352 - val_loss: 0.1610 - val_sparse_categorical_accuracy: 0.9672 - val_cluster_cost: 7.2332e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0352\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 39s 172ms/step - loss: 0.1282 - sparse_categorical_accuracy: 0.9704 - cluster_cost: 7.7474e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0352 - val_loss: 0.1554 - val_sparse_categorical_accuracy: 0.9683 - val_cluster_cost: 8.1755e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0352\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 39s 174ms/step - loss: 0.1243 - sparse_categorical_accuracy: 0.9710 - cluster_cost: 8.5436e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0352 - val_loss: 0.1486 - val_sparse_categorical_accuracy: 0.9722 - val_cluster_cost: 8.7002e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0352\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 40s 178ms/step - loss: 0.1206 - sparse_categorical_accuracy: 0.9725 - cluster_cost: 8.9545e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0352 - val_loss: 0.1426 - val_sparse_categorical_accuracy: 0.9706 - val_cluster_cost: 8.9251e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0352\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 40s 177ms/step - loss: 0.1184 - sparse_categorical_accuracy: 0.9742 - cluster_cost: 9.2027e-04 - separation_cost: 1.3563e-07 - l1_weights_cost: 0.0352 - val_loss: 0.1384 - val_sparse_categorical_accuracy: 0.9739 - val_cluster_cost: 0.0010 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0352\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 38s 171ms/step - loss: 0.1170 - sparse_categorical_accuracy: 0.9743 - cluster_cost: 0.0011 - separation_cost: 5.4253e-07 - l1_weights_cost: 0.0352 - val_loss: 0.1350 - val_sparse_categorical_accuracy: 0.9767 - val_cluster_cost: 0.0012 - val_separation_cost: 3.2124e-06 - val_l1_weights_cost: 0.0352\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 38s 169ms/step - loss: 0.1145 - sparse_categorical_accuracy: 0.9747 - cluster_cost: 0.0012 - separation_cost: 1.0851e-06 - l1_weights_cost: 0.0352 - val_loss: 0.1325 - val_sparse_categorical_accuracy: 0.9739 - val_cluster_cost: 0.0012 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0352\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 41s 180ms/step - loss: 0.1127 - sparse_categorical_accuracy: 0.9756 - cluster_cost: 0.0012 - separation_cost: 3.9334e-06 - l1_weights_cost: 0.0352 - val_loss: 0.1291 - val_sparse_categorical_accuracy: 0.9744 - val_cluster_cost: 0.0012 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0352\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/quadrants/model_quadrants_stage8\n",
      "INFO:tensorflow:Assets written to: ./saved_models/quadrants/model_quadrants_stage8/assets\n",
      "--------------------\n",
      "TRAINING STAGE = 9\n",
      "--------------------\n",
      "Running Prototype Push\n",
      "8/8 [==============================] - 9s 1s/step\n",
      "Performing push of prototypes.\n",
      "Push complete.\n",
      "\n",
      "   conv_0 --> False\n",
      "   maxpooling_0 --> False\n",
      "   conv_1 --> False\n",
      "   maxpooling_1 --> False\n",
      "   first_1x1_conv --> False\n",
      "   second_1x1_conv --> False\n",
      "   prototype --> False\n",
      "   final_weights --> True\n",
      "learning rate = 1e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -2.1529968\n",
      "    np.max(model.layers[-3].get_weights()[1]): 5.0716286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 16s 67ms/step - loss: 0.1859 - sparse_categorical_accuracy: 0.9631 - cluster_cost: 3.6214e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0244 - val_loss: 0.1950 - val_sparse_categorical_accuracy: 0.9594 - val_cluster_cost: 3.4265e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0200\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 14s 62ms/step - loss: 0.1814 - sparse_categorical_accuracy: 0.9607 - cluster_cost: 3.6214e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0195 - val_loss: 0.1942 - val_sparse_categorical_accuracy: 0.9567 - val_cluster_cost: 3.4265e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0180\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 15s 66ms/step - loss: 0.1801 - sparse_categorical_accuracy: 0.9607 - cluster_cost: 3.6214e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0180 - val_loss: 0.1882 - val_sparse_categorical_accuracy: 0.9594 - val_cluster_cost: 3.4265e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0167\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.1783 - sparse_categorical_accuracy: 0.9594 - cluster_cost: 3.6214e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0168 - val_loss: 0.1881 - val_sparse_categorical_accuracy: 0.9578 - val_cluster_cost: 3.4265e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0169\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.1783 - sparse_categorical_accuracy: 0.9593 - cluster_cost: 3.6214e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0171 - val_loss: 0.1940 - val_sparse_categorical_accuracy: 0.9567 - val_cluster_cost: 3.4265e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0177\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.1772 - sparse_categorical_accuracy: 0.9601 - cluster_cost: 3.6214e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0162 - val_loss: 0.1867 - val_sparse_categorical_accuracy: 0.9594 - val_cluster_cost: 3.4265e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0159\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.1757 - sparse_categorical_accuracy: 0.9600 - cluster_cost: 3.6214e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0159 - val_loss: 0.1848 - val_sparse_categorical_accuracy: 0.9594 - val_cluster_cost: 3.4265e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0166\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.1769 - sparse_categorical_accuracy: 0.9596 - cluster_cost: 3.6214e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0157 - val_loss: 0.1840 - val_sparse_categorical_accuracy: 0.9589 - val_cluster_cost: 3.4265e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0163\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.1757 - sparse_categorical_accuracy: 0.9606 - cluster_cost: 3.6214e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0153 - val_loss: 0.1825 - val_sparse_categorical_accuracy: 0.9594 - val_cluster_cost: 3.4265e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0144\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.1745 - sparse_categorical_accuracy: 0.9594 - cluster_cost: 3.6214e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0146 - val_loss: 0.1825 - val_sparse_categorical_accuracy: 0.9589 - val_cluster_cost: 3.4265e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0148\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/quadrants/model_quadrants_stage9\n",
      "INFO:tensorflow:Assets written to: ./saved_models/quadrants/model_quadrants_stage9/assets\n"
     ]
    }
   ],
   "source": [
    "imp.reload(push_prototypes)\n",
    "NEPOCHS    = settings['nepochs']\n",
    "STAGE_LIST = (0,1,2,3,4,5,6,7,8,9)#range(len(NEPOCHS))#(1,2,3,4,5)#range(len(NEPOCHS))\n",
    "\n",
    "for stage in STAGE_LIST:\n",
    "    \n",
    "    print('--------------------')\n",
    "    print('TRAINING STAGE = ' + str(stage))\n",
    "    print('--------------------')\n",
    "\n",
    "    # load previously trained stage, unless it is the 0th stage\n",
    "    if(stage != 0):\n",
    "        tf.keras.backend.clear_session()\n",
    "        model_filename = model_dir + 'model_' + EXP_NAME + '_stage' + str(stage-1)\n",
    "#         model = common_functions.load_model(model_filename)\n",
    "        model.load_weights(model_filename)\n",
    "        \n",
    "    # learn layers (during even numbered stages)\n",
    "    if(stage % 2 == 0):\n",
    "        # train prototypes layers (and possibly CNN layers)\n",
    "        if(settings['pretrain']==False and settings['train_cnn_in_stage'] == True):\n",
    "            model = network.set_trainable_layers(model, [True,True,True,False])            \n",
    "        elif(settings['train_cnn_in_stage'] == False or stage==0):\n",
    "            model = network.set_trainable_layers(model, [False,True,True,False])\n",
    "        elif(settings['train_cnn_in_stage'] == True):\n",
    "            model = network.set_trainable_layers(model, [True,True,True,False])            \n",
    "        elif(stage >= settings['train_cnn_in_stage']):\n",
    "            model = network.set_trainable_layers(model, [True,True,True,False])            \n",
    "        else:\n",
    "            model = network.set_trainable_layers(model, [False,True,True,False])\n",
    "    else:\n",
    "        #.......................................................\n",
    "        # push the prototypes\n",
    "        #.......................................................        \n",
    "        model, push_info = push_prototypes.push(model, \n",
    "                                                [X_train,prototypes_of_correct_class_train], \n",
    "                                                prototypes_of_correct_class_train, \n",
    "                                                perform_push=True,\n",
    "                                                batch_size=BATCH_SIZE_PREDICT,\n",
    "                                                verbose=False,\n",
    "                                               )        \n",
    "        print('Push complete.\\n')            \n",
    "\n",
    "        # train weights layer only\n",
    "        model = network.set_trainable_layers(model, [False,False,False,True])        \n",
    "\n",
    "    #.......................................................\n",
    "    # compile the model\n",
    "    #.......................................................\n",
    "    if(stage>=settings['cut_lr_stage']):\n",
    "        lr_factor = 10.**(np.floor((stage-settings['cut_lr_stage']+2)/2))\n",
    "    else:\n",
    "        lr_factor = 1.\n",
    "    if(LR_INIT/lr_factor<settings['min_lr']):\n",
    "        lr_factor = LR_INIT/settings['min_lr']\n",
    "    print('learning rate = ' + str(np.asarray(LR_INIT/lr_factor,dtype='float32')))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=np.asarray(LR_INIT/lr_factor,dtype='float32'), \n",
    "        ),\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics = metrics_list,\n",
    "    )\n",
    "#     model.summary()\n",
    "    ic(np.min(model.layers[-3].get_weights()[1]),np.max(model.layers[-3].get_weights()[1]))\n",
    "\n",
    "    #.......................................................\n",
    "    # train the model\n",
    "    #.......................................................\n",
    "    print('Training the model...')    \n",
    "    \n",
    "    tf.random.set_seed(RANDOM_SEED)   \n",
    "    np.random.seed(RANDOM_SEED)    \n",
    "    history = model.fit(\n",
    "        [X_train,prototypes_of_correct_class_train],\n",
    "        y_train,\n",
    "        validation_data=([[X_val,prototypes_of_correct_class_val]], [y_val]),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=NEPOCHS[stage],\n",
    "        shuffle=True,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list\n",
    "    )\n",
    "    print('Training complete.\\n')            \n",
    "        \n",
    "\n",
    "    # save the model at this training stage\n",
    "    model_filename = model_dir + 'model_' + EXP_NAME + '_stage' + str(stage)\n",
    "    common_functions.save_model(model, model_filename) \n",
    "    \n",
    "    #.......................................................\n",
    "    # plot results\n",
    "    #.......................................................  \n",
    "    try:\n",
    "        # plot loss history of the model\n",
    "        plots.plot_loss_history(history)\n",
    "        plt.savefig(model_diagnostics_dir + EXP_NAME + '_loss_history_stage' + str(stage) + '.png', dpi=dpiFig)    \n",
    "        plt.close()\n",
    "\n",
    "        # plot the weights\n",
    "        plots.plot_weights(model, PROTOTYPES_PER_CLASS)    \n",
    "        plt.savefig(model_diagnostics_dir + EXP_NAME + '_weights_stage' + str(stage) + '.png', dpi=dpiFig)\n",
    "        plt.close()\n",
    "    except:\n",
    "        print('not making plots...')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b663b0-f667-4172-a71a-7344b14b9590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
