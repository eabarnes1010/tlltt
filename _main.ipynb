{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f6a48b-bab3-4333-abf3-07711e94b616",
   "metadata": {},
   "source": [
    "# This Looks Like That There\n",
    "\n",
    "Main training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf3dd4-d4af-4c8c-89f6-67097628c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import imp #imp.reload(module)\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from icecream import ic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import network\n",
    "import experiment_settings \n",
    "import data_functions\n",
    "import push_prototypes\n",
    "import plots\n",
    "import common_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e0dba3-9a8a-4d45-b00b-7aaface5fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Elizabeth A. Barnes and Randal J Barnes\"\n",
    "__version__ = \"1 December 2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18825d5a-a951-4a29-8dbd-1b1956974b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.facecolor'] = 'white'\n",
    "mpl.rcParams['figure.dpi']= 150\n",
    "dpiFig = 300."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce58c40-dd37-43ea-9ad3-6d6b56b7d166",
   "metadata": {},
   "source": [
    "## Print the detailed system info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e923341-795f-428a-b5bf-d8cafdce1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"python version = {sys.version}\")\n",
    "print(f\"numpy version = {np.__version__}\")\n",
    "print(f\"tensorflow version = {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b515327-ece1-478c-9c99-0d3979739cbe",
   "metadata": {},
   "source": [
    "## Define experiment settings and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db315d0-951f-4fe1-88b7-168343dfe3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = 'mjo_seed28'#'quadrants_testcase'\n",
    "\n",
    "imp.reload(experiment_settings)\n",
    "settings = experiment_settings.get_settings(EXP_NAME)\n",
    "\n",
    "imp.reload(common_functions)\n",
    "model_dir, model_diagnostics_dir, vizualization_dir = common_functions.get_exp_directories(EXP_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c333c24-ae7d-43d3-bc87-09fc8e7d8e89",
   "metadata": {},
   "source": [
    "## Define the network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3005d411-649b-484a-8c3e-fc23500e11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED          = settings['random_seed']\n",
    "BATCH_SIZE_PREDICT   = settings['batch_size_predict']\n",
    "BATCH_SIZE           = settings['batch_size']\n",
    "NLAYERS              = settings['nlayers']\n",
    "NFILTERS             = settings['nfilters']   \n",
    "assert(len(NFILTERS)==NLAYERS)\n",
    "\n",
    "NCLASSES             = settings['nclasses']\n",
    "PROTOTYPES_PER_CLASS = settings['prototypes_per_class']\n",
    "NPROTOTYPES          = np.sum(PROTOTYPES_PER_CLASS)\n",
    "\n",
    "NEPOCHS              = settings['nepochs']\n",
    "LR_INIT              = settings['lr']\n",
    "LR_CALLBACK_EPOCH    = settings['lr_cb_epoch']\n",
    "PATIENCE             = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ab2e28-c92f-4c2d-a5d2-96dcfd9625a3",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb857807-8efc-485b-8be6-29751f6a4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521a7140-1796-429f-ad34-1ff25ecca436",
   "metadata": {},
   "source": [
    "## Get and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f94434b-18eb-408a-8810-af9f27cdf522",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(data_functions)\n",
    "DATA_NAME = settings['data_name']\n",
    "DATA_DIR = settings['data_dir']\n",
    "\n",
    "if(EXP_NAME[:3]=='mjo'):\n",
    "\n",
    "    labels, data, lat, lon, time = data_functions.load_mjo_data(DATA_DIR)\n",
    "    X_train, y_train, time_train, X_val, y_val, time_val, X_test, y_test, time_test = data_functions.get_and_process_mjo_data(labels,\n",
    "                                                                                         data,\n",
    "                                                                                         time,\n",
    "                                                                                         rng, \n",
    "                                                                                         colored=settings['colored'],\n",
    "                                                                                         standardize=settings['standardize'],\n",
    "                                                                                         shuffle=settings['shuffle'],\n",
    "                                                                                        )        \n",
    "elif(EXP_NAME[:9]=='quadrants'):\n",
    "    filename = DATA_DIR + DATA_NAME + '.mat'\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, lat, lon = data_functions.get_and_process_data(filename, \n",
    "                                                                                        rng, \n",
    "                                                                                        colored=settings['colored'],\n",
    "                                                                                        standardize=settings['standardize'],\n",
    "                                                                                        shuffle=settings['shuffle'],\n",
    "                                                                                        )      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b621855-61ee-4e16-9948-9f2bcf61721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_class_mask = network.createClassIdentity(PROTOTYPES_PER_CLASS)\n",
    "\n",
    "prototypes_of_correct_class_train = np.zeros((len(y_train),NPROTOTYPES))\n",
    "for i in range(0,prototypes_of_correct_class_train.shape[0]):\n",
    "    prototypes_of_correct_class_train[i,:] = proto_class_mask[:,int(y_train[i])]\n",
    "    \n",
    "prototypes_of_correct_class_val   = np.zeros((len(y_val),NPROTOTYPES))    \n",
    "for i in range(0,prototypes_of_correct_class_val.shape[0]):\n",
    "    prototypes_of_correct_class_val[i,:] = proto_class_mask[:,int(y_val[i])]\n",
    "\n",
    "prototypes_of_correct_class_test   = np.zeros((len(y_test),NPROTOTYPES))    \n",
    "for i in range(0,prototypes_of_correct_class_test.shape[0]):\n",
    "    prototypes_of_correct_class_test[i,:] = proto_class_mask[:,int(y_test[i])]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2b2787-9d90-4955-90a4-1a6526c918e9",
   "metadata": {},
   "source": [
    "## Define the training callbacks and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ca24eb-ab9c-4db0-82c8-94980521c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < LR_CALLBACK_EPOCH:\n",
    "        return np.round(lr,8)\n",
    "    else:\n",
    "        if(epoch % 2 == 0):\n",
    "            return lr/2.\n",
    "        else:\n",
    "            return lr\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)    \n",
    "    \n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_sparse_categorical_accuracy', \n",
    "    mode='max',\n",
    "    patience=settings['patience'], \n",
    "    restore_best_weights=True, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks_list = [\n",
    "#     lr_callback,\n",
    "#     es_callback,\n",
    "]            \n",
    "\n",
    "# metrics\n",
    "metrics_list = [\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa63e6-adc0-40b0-92a1-16dd4cc806f6",
   "metadata": {},
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87cc2fb-5cf9-4029-824c-c24262ccb729",
   "metadata": {},
   "outputs": [],
   "source": [
    "__ = imp.reload(network)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = network.build_model(\n",
    "    nlayers              = NLAYERS,\n",
    "    nfilters             = NFILTERS,\n",
    "    input_shape          = X_train.shape[1:],\n",
    "    output_shape         = NCLASSES,\n",
    "    prototypes_per_class = PROTOTYPES_PER_CLASS,\n",
    "    network_seed         = RANDOM_SEED,    \n",
    "    prototype_channels   = settings['prototype_channels'],    \n",
    "    coeff_cluster        = settings['coeff_cluster'],\n",
    "    coeff_separation     = settings['coeff_separation'],\n",
    "    coeff_l1             = settings['coeff_l1'],\n",
    "    incorrect_strength   = settings['incorrect_strength'],\n",
    "    double_conv          = settings['double_conv'],\n",
    "    kernel_l1_coeff      = 0.0,#settings['kernel_l1_coeff'],\n",
    "    kernel_l2_coeff      = 0.0,#settings['kernel_l2_coeff'],\n",
    "    drop_rate            = 0.0,\n",
    "    drop_rate_final      = 0.0,        \n",
    "    \n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404175a3-bc7c-4f2e-8445-3985983c8458",
   "metadata": {},
   "source": [
    "## Load pre-trained weights into convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dbbe1c-cf25-489c-898a-905a537609af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(settings['pretrain'] == True):\n",
    "\n",
    "    if(settings['pretrain_exp'] is None):\n",
    "        PRETRAINED_MODEL = model_dir + 'pretrained_model_' + EXP_NAME \n",
    "    else:\n",
    "        PRETRAINED_MODEL = './saved_models/' + settings['pretrain_exp'] \n",
    "\n",
    "    print('loading pretrained convolutional layers from ' + PRETRAINED_MODEL)\n",
    "    pretrained_model = tf.keras.models.load_model(PRETRAINED_MODEL)\n",
    "\n",
    "    for layer in range(1,len(model.layers)):\n",
    "        if(model.layers[layer].name[:4]=='conv'):\n",
    "            print('   loading pretrained weights for --> ' + model.layers[layer].name)\n",
    "            model.layers[layer].set_weights(pretrained_model.layers[layer].get_weights())\n",
    "else:\n",
    "    print('no pretrained model specified. keeping random initialized weights.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e13996-3403-43f2-9544-173155b4ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise ValueError('here')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea5c00a-658f-4597-a2fe-57e838c1db8d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b26f9-6628-4c46-b1d3-dda086aa468f",
   "metadata": {},
   "source": [
    "# Run Training Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab06f5d-7264-4ec3-ba4b-b29712e442e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(network)\n",
    "imp.reload(plots)\n",
    "imp.reload(push_prototypes)\n",
    "imp.reload(experiment_settings)\n",
    "settings = experiment_settings.get_settings(EXP_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e32234e-5283-48e5-8024-d1fd279e80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic(np.shape(X_train))\n",
    "ic(np.shape(prototypes_of_correct_class_train))\n",
    "ic(np.shape(prototypes_of_correct_class_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b03cd-4810-4c70-b8fa-3fb05caa3e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(push_prototypes)\n",
    "NEPOCHS    = settings['nepochs']\n",
    "STAGE_LIST = (0,1,2,3,4,5,6,7,8,9)#range(len(NEPOCHS))#(1,2,3,4,5)#range(len(NEPOCHS))\n",
    "\n",
    "for stage in STAGE_LIST:\n",
    "    \n",
    "    print('--------------------')\n",
    "    print('TRAINING STAGE = ' + str(stage))\n",
    "    print('--------------------')\n",
    "\n",
    "    # load previously trained stage, unless it is the 0th stage\n",
    "    if(stage != 0):\n",
    "        tf.keras.backend.clear_session()\n",
    "        model_filename = model_dir + 'model_' + EXP_NAME + '_stage' + str(stage-1)\n",
    "#         model = common_functions.load_model(model_filename)\n",
    "        model.load_weights(model_filename)\n",
    "        \n",
    "    # learn layers (during even numbered stages)\n",
    "    if(stage % 2 == 0):\n",
    "        # train prototypes layers (and possibly CNN layers)\n",
    "        if(settings['pretrain']==False and settings['train_cnn_in_stage'] == True):\n",
    "            model = network.set_trainable_layers(model, [True,True,True,False])            \n",
    "        elif(settings['train_cnn_in_stage'] == False or stage==0):\n",
    "            model = network.set_trainable_layers(model, [False,True,True,False])\n",
    "        elif(settings['train_cnn_in_stage'] == True):\n",
    "            model = network.set_trainable_layers(model, [True,True,True,False])            \n",
    "        elif(stage >= settings['train_cnn_in_stage']):\n",
    "            model = network.set_trainable_layers(model, [True,True,True,False])            \n",
    "        else:\n",
    "            model = network.set_trainable_layers(model, [False,True,True,False])\n",
    "    else:\n",
    "        #.......................................................\n",
    "        # push the prototypes\n",
    "        #.......................................................        \n",
    "        model, push_info = push_prototypes.push(model, \n",
    "                                                [X_train,prototypes_of_correct_class_train], \n",
    "                                                prototypes_of_correct_class_train, \n",
    "                                                perform_push=True,\n",
    "                                                batch_size=BATCH_SIZE_PREDICT,\n",
    "                                                verbose=False,\n",
    "                                               )        \n",
    "        print('Push complete.\\n')            \n",
    "\n",
    "        # train weights layer only\n",
    "        model = network.set_trainable_layers(model, [False,False,False,True])        \n",
    "\n",
    "    #.......................................................\n",
    "    # compile the model\n",
    "    #.......................................................\n",
    "    if(stage>=settings['cut_lr_stage']):\n",
    "        lr_factor = 10.**(np.floor((stage-settings['cut_lr_stage']+2)/2))\n",
    "    else:\n",
    "        lr_factor = 1.\n",
    "    if(LR_INIT/lr_factor<settings['min_lr']):\n",
    "        lr_factor = LR_INIT/settings['min_lr']\n",
    "    print('learning rate = ' + str(np.asarray(LR_INIT/lr_factor,dtype='float32')))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=np.asarray(LR_INIT/lr_factor,dtype='float32'), \n",
    "        ),\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics = metrics_list,\n",
    "    )\n",
    "#     model.summary()\n",
    "    ic(np.min(model.layers[-3].get_weights()[1]),np.max(model.layers[-3].get_weights()[1]))\n",
    "\n",
    "    #.......................................................\n",
    "    # train the model\n",
    "    #.......................................................\n",
    "    print('Training the model...')    \n",
    "    \n",
    "    tf.random.set_seed(RANDOM_SEED)   \n",
    "    np.random.seed(RANDOM_SEED)    \n",
    "    history = model.fit(\n",
    "        [X_train,prototypes_of_correct_class_train],\n",
    "        y_train,\n",
    "        validation_data=([[X_val,prototypes_of_correct_class_val]], [y_val]),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=NEPOCHS[stage],\n",
    "        shuffle=True,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list\n",
    "    )\n",
    "    print('Training complete.\\n')            \n",
    "        \n",
    "\n",
    "    # save the model at this training stage\n",
    "    model_filename = model_dir + 'model_' + EXP_NAME + '_stage' + str(stage)\n",
    "    common_functions.save_model(model, model_filename) \n",
    "    \n",
    "    #.......................................................\n",
    "    # plot results\n",
    "    #.......................................................  \n",
    "    try:\n",
    "        # plot loss history of the model\n",
    "        plots.plot_loss_history(history)\n",
    "        plt.savefig(model_diagnostics_dir + EXP_NAME + '_loss_history_stage' + str(stage) + '.png', dpi=dpiFig)    \n",
    "        plt.close()\n",
    "\n",
    "        # plot the weights\n",
    "        plots.plot_weights(model, PROTOTYPES_PER_CLASS)    \n",
    "        plt.savefig(model_diagnostics_dir + EXP_NAME + '_weights_stage' + str(stage) + '.png', dpi=dpiFig)\n",
    "        plt.close()\n",
    "    except:\n",
    "        print('not making plots...')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b663b0-f667-4172-a71a-7344b14b9590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
