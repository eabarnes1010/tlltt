{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f6a48b-bab3-4333-abf3-07711e94b616",
   "metadata": {},
   "source": [
    "# This Looks Like That in Tensorflow\n",
    "\n",
    "Useful Files and Links\n",
    "- Chen et al. (2019)\n",
    "- https://github.com/cfchen-duke/ProtoPNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36bf3dd4-d4af-4c8c-89f6-67097628c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import imp #imp.reload(module)\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from icecream import ic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import network\n",
    "import experiment_settings \n",
    "import data_functions\n",
    "import push_prototypes\n",
    "import plots\n",
    "import common_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e0dba3-9a8a-4d45-b00b-7aaface5fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Elizabeth A. Barnes and Randal J Barnes\"\n",
    "__version__ = \"23 November 2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18825d5a-a951-4a29-8dbd-1b1956974b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.facecolor'] = 'white'\n",
    "mpl.rcParams['figure.dpi']= 150\n",
    "dpiFig = 300."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce58c40-dd37-43ea-9ad3-6d6b56b7d166",
   "metadata": {},
   "source": [
    "## Print the detailed system info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e923341-795f-428a-b5bf-d8cafdce1bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version = 3.9.4 (default, Apr  9 2021, 09:32:38) \n",
      "[Clang 10.0.0 ]\n",
      "numpy version = 1.19.5\n",
      "tensorflow version = 2.5.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"python version = {sys.version}\")\n",
    "print(f\"numpy version = {np.__version__}\")\n",
    "print(f\"tensorflow version = {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b515327-ece1-478c-9c99-0d3979739cbe",
   "metadata": {},
   "source": [
    "## Define experiment settings and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0db315d0-951f-4fe1-88b7-168343dfe3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = 'quadrants'\n",
    "\n",
    "imp.reload(experiment_settings)\n",
    "settings = experiment_settings.get_settings(EXP_NAME)\n",
    "\n",
    "imp.reload(common_functions)\n",
    "model_dir, model_diagnostics_dir, vizualization_dir = common_functions.get_exp_directories(EXP_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c333c24-ae7d-43d3-bc87-09fc8e7d8e89",
   "metadata": {},
   "source": [
    "## Define the network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3005d411-649b-484a-8c3e-fc23500e11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED          = settings['random_seed']\n",
    "BATCH_SIZE_PREDICT   = settings['batch_size_predict']\n",
    "BATCH_SIZE           = settings['batch_size']\n",
    "NLAYERS              = settings['nlayers']\n",
    "NFILTERS             = settings['nfilters']   \n",
    "assert(len(NFILTERS)==NLAYERS)\n",
    "\n",
    "NCLASSES             = settings['nclasses']\n",
    "PROTOTYPES_PER_CLASS = settings['prototypes_per_class']\n",
    "NPROTOTYPES          = np.sum(PROTOTYPES_PER_CLASS)\n",
    "\n",
    "NEPOCHS              = settings['nepochs']\n",
    "LR_INIT              = settings['lr']\n",
    "LR_CALLBACK_EPOCH    = settings['lr_cb_epoch']\n",
    "PATIENCE             = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ab2e28-c92f-4c2d-a5d2-96dcfd9625a3",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb857807-8efc-485b-8be6-29751f6a4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521a7140-1796-429f-ad34-1ff25ecca436",
   "metadata": {},
   "source": [
    "## Get and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f94434b-18eb-408a-8810-af9f27cdf522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./data/data_quadrants.mat\n",
      "shuffling the data before train/validation/test split.\n",
      "raw_data        = (9000, 100, 100, 1)\n",
      "training data   = (7200, 100, 100, 1), (7200,)\n",
      "validation data = (1800, 100, 100, 1), (1800,)\n",
      "test data       = (0, 100, 100, 1), (0,)\n",
      "X_mean          = -8.325328964462919e-05\n",
      "X_std           = 0.1127845155013707\n"
     ]
    }
   ],
   "source": [
    "imp.reload(data_functions)\n",
    "DATA_NAME = settings['data_name']\n",
    "DATA_DIR = settings['data_dir']\n",
    "\n",
    "if(EXP_NAME[:3]=='mjo'):\n",
    "\n",
    "    labels, data, lat, lon, time = data_functions.load_mjo_data(DATA_DIR)\n",
    "    X_train, y_train, time_train, X_val, y_val, time_val, X_test, y_test, time_test = data_functions.get_and_process_mjo_data(labels,\n",
    "                                                                                         data,\n",
    "                                                                                         time,\n",
    "                                                                                         rng, \n",
    "                                                                                         colored=settings['colored'],\n",
    "                                                                                         standardize=settings['standardize'],\n",
    "                                                                                         shuffle=settings['shuffle'],\n",
    "                                                                                        )        \n",
    "elif(EXP_NAME[:9]=='quadrants'):\n",
    "    filename = DATA_DIR + DATA_NAME + '.mat'\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, lat, lon = data_functions.get_and_process_data(filename, \n",
    "                                                                                        rng, \n",
    "                                                                                        colored=settings['colored'],\n",
    "                                                                                        standardize=settings['standardize'],\n",
    "                                                                                        shuffle=settings['shuffle'],\n",
    "                                                                                        )      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b621855-61ee-4e16-9948-9f2bcf61721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_class_mask = network.createClassIdentity(PROTOTYPES_PER_CLASS)\n",
    "\n",
    "prototypes_of_correct_class_train = np.zeros((len(y_train),NPROTOTYPES))\n",
    "for i in range(0,prototypes_of_correct_class_train.shape[0]):\n",
    "    prototypes_of_correct_class_train[i,:] = proto_class_mask[:,int(y_train[i])]\n",
    "    \n",
    "prototypes_of_correct_class_val   = np.zeros((len(y_val),NPROTOTYPES))    \n",
    "for i in range(0,prototypes_of_correct_class_val.shape[0]):\n",
    "    prototypes_of_correct_class_val[i,:] = proto_class_mask[:,int(y_val[i])]\n",
    "\n",
    "prototypes_of_correct_class_test   = np.zeros((len(y_test),NPROTOTYPES))    \n",
    "for i in range(0,prototypes_of_correct_class_test.shape[0]):\n",
    "    prototypes_of_correct_class_test[i,:] = proto_class_mask[:,int(y_test[i])]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2b2787-9d90-4955-90a4-1a6526c918e9",
   "metadata": {},
   "source": [
    "## Define the training callbacks and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64ca24eb-ab9c-4db0-82c8-94980521c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < LR_CALLBACK_EPOCH:\n",
    "        return np.round(lr,8)\n",
    "    else:\n",
    "        if(epoch % 2 == 0):\n",
    "            return lr/2.\n",
    "        else:\n",
    "            return lr\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)    \n",
    "    \n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_sparse_categorical_accuracy', \n",
    "    mode='max',\n",
    "    patience=settings['patience'], \n",
    "    restore_best_weights=True, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks_list = [\n",
    "#     lr_callback,\n",
    "#     es_callback,\n",
    "]            \n",
    "\n",
    "# metrics\n",
    "metrics_list = [\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa63e6-adc0-40b0-92a1-16dd4cc806f6",
   "metadata": {},
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c87cc2fb-5cf9-4029-824c-c24262ccb729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[32, 32]\n",
      "(100, 100, 1)\n",
      "3\n",
      "[5, 5, 5]\n",
      "30\n",
      "False\n",
      "0.17197201619672103\n",
      "-0.017197201619672104\n",
      "0.5\n",
      "-0.5\n",
      "False\n",
      "8\n",
      "128\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "False\n",
      "Model: \"full_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, 100, 100, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv2D)                 (None, 100, 100, 32) 320         inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 100, 100, 32) 0           conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxpooling_0 (AveragePooling2D) (None, 50, 50, 32)   0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 50, 50, 32)   9248        maxpooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50, 50, 32)   0           conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "maxpooling_1 (AveragePooling2D) (None, 25, 25, 32)   0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "first_1x1_conv (Conv2D)         (None, 25, 25, 128)  4224        maxpooling_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "second_1x1_conv (Conv2D)        (None, 25, 25, 128)  16512       first_1x1_conv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "prototypes_of_correct_class (In [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "prototype (Prototype)           (None, 15)           11295       second_1x1_conv[0][0]            \n",
      "                                                                 prototypes_of_correct_class[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "final_weights (FinalWeights)    (None, 3)            45          prototype[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax_output (Softmax)        (None, 3)            0           final_weights[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 41,644\n",
      "Trainable params: 41,644\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "__ = imp.reload(network)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = network.build_model(\n",
    "    nlayers              = NLAYERS,\n",
    "    nfilters             = NFILTERS,\n",
    "    input_shape          = X_train.shape[1:],\n",
    "    output_shape         = NCLASSES,\n",
    "    prototypes_per_class = PROTOTYPES_PER_CLASS,\n",
    "    network_seed         = RANDOM_SEED,    \n",
    "    prototype_channels   = settings['prototype_channels'],    \n",
    "    coeff_cluster        = settings['coeff_cluster'],\n",
    "    coeff_separation     = settings['coeff_separation'],\n",
    "    coeff_l1             = settings['coeff_l1'],\n",
    "    incorrect_strength   = settings['incorrect_strength'],\n",
    "    double_conv          = settings['double_conv'],\n",
    "    kernel_l1_coeff      = 0.0,#settings['kernel_l1_coeff'],\n",
    "    kernel_l2_coeff      = 0.0,#settings['kernel_l2_coeff'],\n",
    "    drop_rate            = 0.0,\n",
    "    drop_rate_final      = 0.0,        \n",
    "    \n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404175a3-bc7c-4f2e-8445-3985983c8458",
   "metadata": {},
   "source": [
    "## Load pre-trained weights into convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8dbbe1c-cf25-489c-898a-905a537609af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained convolutional layers from ./saved_models/quadrants/pretrained_model_quadrants\n",
      "   loading pretrained weights for --> conv_0\n",
      "   loading pretrained weights for --> conv_1\n"
     ]
    }
   ],
   "source": [
    "if(settings['pretrain'] == True):\n",
    "\n",
    "    if(settings['pretrain_exp'] is None):\n",
    "        PRETRAINED_MODEL = model_dir + 'pretrained_model_' + EXP_NAME \n",
    "    else:\n",
    "        PRETRAINED_MODEL = './saved_models/' + settings['pretrain_exp'] \n",
    "\n",
    "    print('loading pretrained convolutional layers from ' + PRETRAINED_MODEL)\n",
    "    pretrained_model = tf.keras.models.load_model(PRETRAINED_MODEL)\n",
    "\n",
    "    for layer in range(1,len(model.layers)):\n",
    "        if(model.layers[layer].name[:4]=='conv'):\n",
    "            print('   loading pretrained weights for --> ' + model.layers[layer].name)\n",
    "            model.layers[layer].set_weights(pretrained_model.layers[layer].get_weights())\n",
    "else:\n",
    "    print('no pretrained model specified. keeping random initialized weights.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1e13996-3403-43f2-9544-173155b4ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise ValueError('here')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea5c00a-658f-4597-a2fe-57e838c1db8d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b26f9-6628-4c46-b1d3-dda086aa468f",
   "metadata": {},
   "source": [
    "# Run Training Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ab06f5d-7264-4ec3-ba4b-b29712e442e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(network)\n",
    "imp.reload(plots)\n",
    "imp.reload(push_prototypes)\n",
    "imp.reload(experiment_settings)\n",
    "settings = experiment_settings.get_settings(EXP_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e32234e-5283-48e5-8024-d1fd279e80b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.shape(X_train): (7200, 100, 100, 1)\n",
      "ic| np.shape(prototypes_of_correct_class_train): (7200, 15)\n",
      "ic| np.shape(prototypes_of_correct_class_train): (7200, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7200, 15)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(np.shape(X_train))\n",
    "ic(np.shape(prototypes_of_correct_class_train))\n",
    "ic(np.shape(prototypes_of_correct_class_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "933b03cd-4810-4c70-b8fa-3fb05caa3e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): 0.0\n",
      "    np.max(model.layers[-3].get_weights()[1]): 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 0\n",
      "--------------------\n",
      "   conv_0 --> False\n",
      "   maxpooling_0 --> False\n",
      "   conv_1 --> False\n",
      "   maxpooling_1 --> False\n",
      "   first_1x1_conv --> True\n",
      "   second_1x1_conv --> True\n",
      "   prototype --> True\n",
      "   final_weights --> False\n",
      "learning rate = 0.01\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 8.5361 - sparse_categorical_accuracy: 0.6253 - cluster_cost: 1.6270 - separation_cost: 1.5892 - l1_weights_cost: 7.5000 - val_loss: 7.9238 - val_sparse_categorical_accuracy: 0.8411 - val_cluster_cost: 0.3871 - val_separation_cost: 0.4295 - val_l1_weights_cost: 7.5000\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 7.8278 - sparse_categorical_accuracy: 0.8903 - cluster_cost: 0.2994 - separation_cost: 0.3510 - l1_weights_cost: 7.5000 - val_loss: 7.6999 - val_sparse_categorical_accuracy: 0.9444 - val_cluster_cost: 0.2291 - val_separation_cost: 0.2845 - val_l1_weights_cost: 7.5000\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 7.6792 - sparse_categorical_accuracy: 0.9472 - cluster_cost: 0.2014 - separation_cost: 0.2619 - l1_weights_cost: 7.5000 - val_loss: 7.6586 - val_sparse_categorical_accuracy: 0.9611 - val_cluster_cost: 0.2398 - val_separation_cost: 0.3031 - val_l1_weights_cost: 7.5000\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 12s 51ms/step - loss: 7.6480 - sparse_categorical_accuracy: 0.9582 - cluster_cost: 0.1816 - separation_cost: 0.2427 - l1_weights_cost: 7.5000 - val_loss: 7.6332 - val_sparse_categorical_accuracy: 0.9722 - val_cluster_cost: 0.2316 - val_separation_cost: 0.2991 - val_l1_weights_cost: 7.5000\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 7.6409 - sparse_categorical_accuracy: 0.9606 - cluster_cost: 0.1765 - separation_cost: 0.2299 - l1_weights_cost: 7.5000 - val_loss: 7.6453 - val_sparse_categorical_accuracy: 0.9550 - val_cluster_cost: 0.1852 - val_separation_cost: 0.2384 - val_l1_weights_cost: 7.5000\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 7.6346 - sparse_categorical_accuracy: 0.9638 - cluster_cost: 0.1686 - separation_cost: 0.2256 - l1_weights_cost: 7.5000 - val_loss: 7.6209 - val_sparse_categorical_accuracy: 0.9667 - val_cluster_cost: 0.1743 - val_separation_cost: 0.2231 - val_l1_weights_cost: 7.5000\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 7.6301 - sparse_categorical_accuracy: 0.9651 - cluster_cost: 0.1604 - separation_cost: 0.2105 - l1_weights_cost: 7.5000 - val_loss: 7.6134 - val_sparse_categorical_accuracy: 0.9706 - val_cluster_cost: 0.1554 - val_separation_cost: 0.2097 - val_l1_weights_cost: 7.5000\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 7.6269 - sparse_categorical_accuracy: 0.9665 - cluster_cost: 0.1705 - separation_cost: 0.2262 - l1_weights_cost: 7.5000 - val_loss: 7.5906 - val_sparse_categorical_accuracy: 0.9783 - val_cluster_cost: 0.1439 - val_separation_cost: 0.1881 - val_l1_weights_cost: 7.5000\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 7.6311 - sparse_categorical_accuracy: 0.9656 - cluster_cost: 0.1695 - separation_cost: 0.2274 - l1_weights_cost: 7.5000 - val_loss: 7.6034 - val_sparse_categorical_accuracy: 0.9694 - val_cluster_cost: 0.1417 - val_separation_cost: 0.1942 - val_l1_weights_cost: 7.5000\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 7.6184 - sparse_categorical_accuracy: 0.9681 - cluster_cost: 0.1499 - separation_cost: 0.2064 - l1_weights_cost: 7.5000 - val_loss: 7.5984 - val_sparse_categorical_accuracy: 0.9739 - val_cluster_cost: 0.1587 - val_separation_cost: 0.2128 - val_l1_weights_cost: 7.5000\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/quadrants/model_quadrants_stage0\n",
      "INFO:tensorflow:Assets written to: ./saved_models/quadrants/model_quadrants_stage0/assets\n",
      "--------------------\n",
      "TRAINING STAGE = 1\n",
      "--------------------\n",
      "Running Prototype Push\n",
      "8/8 [==============================] - 5s 563ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -0.71230096\n",
      "    np.max(model.layers[-3].get_weights()[1]): 3.1816795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing push of prototypes.\n",
      "Push complete.\n",
      "\n",
      "   conv_0 --> False\n",
      "   maxpooling_0 --> False\n",
      "   conv_1 --> False\n",
      "   maxpooling_1 --> False\n",
      "   first_1x1_conv --> False\n",
      "   second_1x1_conv --> False\n",
      "   prototype --> False\n",
      "   final_weights --> True\n",
      "learning rate = 0.01\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 7s 29ms/step - loss: 1.9873 - sparse_categorical_accuracy: 0.9340 - cluster_cost: 0.0093 - separation_cost: 0.0085 - l1_weights_cost: 1.4306 - val_loss: 0.3049 - val_sparse_categorical_accuracy: 0.9428 - val_cluster_cost: 0.0094 - val_separation_cost: 0.0084 - val_l1_weights_cost: 0.0262\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 6s 28ms/step - loss: 0.2875 - sparse_categorical_accuracy: 0.9461 - cluster_cost: 0.0093 - separation_cost: 0.0085 - l1_weights_cost: 0.0277 - val_loss: 0.2469 - val_sparse_categorical_accuracy: 0.9489 - val_cluster_cost: 0.0094 - val_separation_cost: 0.0084 - val_l1_weights_cost: 0.0232\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 6s 28ms/step - loss: 0.2462 - sparse_categorical_accuracy: 0.9465 - cluster_cost: 0.0093 - separation_cost: 0.0085 - l1_weights_cost: 0.0286 - val_loss: 0.2280 - val_sparse_categorical_accuracy: 0.9528 - val_cluster_cost: 0.0094 - val_separation_cost: 0.0084 - val_l1_weights_cost: 0.0350\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 6s 28ms/step - loss: 0.2194 - sparse_categorical_accuracy: 0.9493 - cluster_cost: 0.0093 - separation_cost: 0.0085 - l1_weights_cost: 0.0272 - val_loss: 0.2015 - val_sparse_categorical_accuracy: 0.9478 - val_cluster_cost: 0.0094 - val_separation_cost: 0.0084 - val_l1_weights_cost: 0.0249\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 6s 28ms/step - loss: 0.2018 - sparse_categorical_accuracy: 0.9488 - cluster_cost: 0.0093 - separation_cost: 0.0085 - l1_weights_cost: 0.0273 - val_loss: 0.1871 - val_sparse_categorical_accuracy: 0.9511 - val_cluster_cost: 0.0094 - val_separation_cost: 0.0084 - val_l1_weights_cost: 0.0241\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 6s 28ms/step - loss: 0.1955 - sparse_categorical_accuracy: 0.9503 - cluster_cost: 0.0093 - separation_cost: 0.0085 - l1_weights_cost: 0.0310 - val_loss: 0.1996 - val_sparse_categorical_accuracy: 0.9456 - val_cluster_cost: 0.0094 - val_separation_cost: 0.0084 - val_l1_weights_cost: 0.0313\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 7s 29ms/step - loss: 0.1849 - sparse_categorical_accuracy: 0.9489 - cluster_cost: 0.0093 - separation_cost: 0.0085 - l1_weights_cost: 0.0276 - val_loss: 0.1902 - val_sparse_categorical_accuracy: 0.9478 - val_cluster_cost: 0.0094 - val_separation_cost: 0.0084 - val_l1_weights_cost: 0.0359\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 7s 30ms/step - loss: 0.1846 - sparse_categorical_accuracy: 0.9508 - cluster_cost: 0.0093 - separation_cost: 0.0085 - l1_weights_cost: 0.0279 - val_loss: 0.1844 - val_sparse_categorical_accuracy: 0.9506 - val_cluster_cost: 0.0094 - val_separation_cost: 0.0084 - val_l1_weights_cost: 0.0357\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 7s 30ms/step - loss: 0.1884 - sparse_categorical_accuracy: 0.9501 - cluster_cost: 0.0093 - separation_cost: 0.0085 - l1_weights_cost: 0.0324 - val_loss: 0.1991 - val_sparse_categorical_accuracy: 0.9478 - val_cluster_cost: 0.0094 - val_separation_cost: 0.0084 - val_l1_weights_cost: 0.0479\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 7s 29ms/step - loss: 0.1951 - sparse_categorical_accuracy: 0.9496 - cluster_cost: 0.0093 - separation_cost: 0.0085 - l1_weights_cost: 0.0370 - val_loss: 0.1864 - val_sparse_categorical_accuracy: 0.9511 - val_cluster_cost: 0.0094 - val_separation_cost: 0.0084 - val_l1_weights_cost: 0.0352\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/quadrants/model_quadrants_stage1\n",
      "INFO:tensorflow:Assets written to: ./saved_models/quadrants/model_quadrants_stage1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -0.71230096\n",
      "    np.max(model.layers[-3].get_weights()[1]): 3.1816795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 2\n",
      "--------------------\n",
      "   conv_0 --> True\n",
      "   maxpooling_0 --> True\n",
      "   conv_1 --> True\n",
      "   maxpooling_1 --> True\n",
      "   first_1x1_conv --> True\n",
      "   second_1x1_conv --> True\n",
      "   prototype --> True\n",
      "   final_weights --> False\n",
      "learning rate = 0.01\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 23s 98ms/step - loss: 0.6108 - sparse_categorical_accuracy: 0.8177 - cluster_cost: 0.2608 - separation_cost: 0.2577 - l1_weights_cost: 0.0352 - val_loss: 0.3557 - val_sparse_categorical_accuracy: 0.8722 - val_cluster_cost: 0.0557 - val_separation_cost: 0.0793 - val_l1_weights_cost: 0.0352\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 22s 99ms/step - loss: 0.2759 - sparse_categorical_accuracy: 0.9276 - cluster_cost: 0.0393 - separation_cost: 0.0625 - l1_weights_cost: 0.0352 - val_loss: 0.2020 - val_sparse_categorical_accuracy: 0.9494 - val_cluster_cost: 0.0266 - val_separation_cost: 0.0468 - val_l1_weights_cost: 0.0352\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 23s 102ms/step - loss: 0.2592 - sparse_categorical_accuracy: 0.9286 - cluster_cost: 0.0418 - separation_cost: 0.0657 - l1_weights_cost: 0.0352 - val_loss: 0.1911 - val_sparse_categorical_accuracy: 0.9561 - val_cluster_cost: 0.0334 - val_separation_cost: 0.0558 - val_l1_weights_cost: 0.0352\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 22s 99ms/step - loss: 0.2181 - sparse_categorical_accuracy: 0.9478 - cluster_cost: 0.0356 - separation_cost: 0.0499 - l1_weights_cost: 0.0352 - val_loss: 0.1741 - val_sparse_categorical_accuracy: 0.9550 - val_cluster_cost: 0.0361 - val_separation_cost: 0.0452 - val_l1_weights_cost: 0.0352\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 22s 97ms/step - loss: 0.1857 - sparse_categorical_accuracy: 0.9585 - cluster_cost: 0.0282 - separation_cost: 0.0448 - l1_weights_cost: 0.0352 - val_loss: 0.1651 - val_sparse_categorical_accuracy: 0.9633 - val_cluster_cost: 0.0311 - val_separation_cost: 0.0478 - val_l1_weights_cost: 0.0352\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 22s 97ms/step - loss: 0.1637 - sparse_categorical_accuracy: 0.9622 - cluster_cost: 0.0289 - separation_cost: 0.0413 - l1_weights_cost: 0.0352 - val_loss: 0.1320 - val_sparse_categorical_accuracy: 0.9756 - val_cluster_cost: 0.0279 - val_separation_cost: 0.0509 - val_l1_weights_cost: 0.0352\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 22s 100ms/step - loss: 0.1602 - sparse_categorical_accuracy: 0.9651 - cluster_cost: 0.0302 - separation_cost: 0.0443 - l1_weights_cost: 0.0352 - val_loss: 0.1340 - val_sparse_categorical_accuracy: 0.9744 - val_cluster_cost: 0.0307 - val_separation_cost: 0.0555 - val_l1_weights_cost: 0.0352\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 23s 104ms/step - loss: 0.1669 - sparse_categorical_accuracy: 0.9614 - cluster_cost: 0.0327 - separation_cost: 0.0397 - l1_weights_cost: 0.0352 - val_loss: 0.1355 - val_sparse_categorical_accuracy: 0.9672 - val_cluster_cost: 0.0275 - val_separation_cost: 0.0333 - val_l1_weights_cost: 0.0352\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 22s 99ms/step - loss: 0.1514 - sparse_categorical_accuracy: 0.9693 - cluster_cost: 0.0321 - separation_cost: 0.0356 - l1_weights_cost: 0.0352 - val_loss: 0.1654 - val_sparse_categorical_accuracy: 0.9628 - val_cluster_cost: 0.0331 - val_separation_cost: 0.0510 - val_l1_weights_cost: 0.0352\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 24s 105ms/step - loss: 0.1729 - sparse_categorical_accuracy: 0.9611 - cluster_cost: 0.0373 - separation_cost: 0.0411 - l1_weights_cost: 0.0352 - val_loss: 0.1182 - val_sparse_categorical_accuracy: 0.9794 - val_cluster_cost: 0.0298 - val_separation_cost: 0.0388 - val_l1_weights_cost: 0.0352\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/quadrants/model_quadrants_stage2\n",
      "INFO:tensorflow:Assets written to: ./saved_models/quadrants/model_quadrants_stage2/assets\n",
      "--------------------\n",
      "TRAINING STAGE = 3\n",
      "--------------------\n",
      "Running Prototype Push\n",
      "8/8 [==============================] - 5s 567ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -1.1491978\n",
      "    np.max(model.layers[-3].get_weights()[1]): 5.5215077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing push of prototypes.\n",
      "Push complete.\n",
      "\n",
      "   conv_0 --> False\n",
      "   maxpooling_0 --> False\n",
      "   conv_1 --> False\n",
      "   maxpooling_1 --> False\n",
      "   first_1x1_conv --> False\n",
      "   second_1x1_conv --> False\n",
      "   prototype --> False\n",
      "   final_weights --> True\n",
      "learning rate = 0.01\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 8s 33ms/step - loss: 1.6199 - sparse_categorical_accuracy: 0.9119 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.3761 - val_loss: 0.7917 - val_sparse_categorical_accuracy: 0.9317 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.2153\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 7s 31ms/step - loss: 0.8620 - sparse_categorical_accuracy: 0.8997 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1748 - val_loss: 0.6522 - val_sparse_categorical_accuracy: 0.9194 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1856\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 7s 30ms/step - loss: 0.7142 - sparse_categorical_accuracy: 0.8983 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1558 - val_loss: 0.4844 - val_sparse_categorical_accuracy: 0.9372 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1519\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 7s 31ms/step - loss: 0.7776 - sparse_categorical_accuracy: 0.8832 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1529 - val_loss: 0.4837 - val_sparse_categorical_accuracy: 0.9411 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1306\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 7s 31ms/step - loss: 0.6470 - sparse_categorical_accuracy: 0.8943 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1252 - val_loss: 0.7683 - val_sparse_categorical_accuracy: 0.8644 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1336\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 7s 30ms/step - loss: 0.8447 - sparse_categorical_accuracy: 0.8790 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1629 - val_loss: 0.8462 - val_sparse_categorical_accuracy: 0.8772 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1032\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 7s 31ms/step - loss: 0.7030 - sparse_categorical_accuracy: 0.8918 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1310 - val_loss: 0.4128 - val_sparse_categorical_accuracy: 0.9483 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1442\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 7s 30ms/step - loss: 0.6760 - sparse_categorical_accuracy: 0.8878 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1283 - val_loss: 0.4865 - val_sparse_categorical_accuracy: 0.9144 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0946\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 6s 29ms/step - loss: 0.5281 - sparse_categorical_accuracy: 0.8989 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1062 - val_loss: 0.4596 - val_sparse_categorical_accuracy: 0.9383 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1503\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 6s 29ms/step - loss: 0.7171 - sparse_categorical_accuracy: 0.8892 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1541 - val_loss: 0.4986 - val_sparse_categorical_accuracy: 0.9022 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1289\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/quadrants/model_quadrants_stage3\n",
      "INFO:tensorflow:Assets written to: ./saved_models/quadrants/model_quadrants_stage3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -1.1491978\n",
      "    np.max(model.layers[-3].get_weights()[1]): 5.5215077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 4\n",
      "--------------------\n",
      "   conv_0 --> True\n",
      "   maxpooling_0 --> True\n",
      "   conv_1 --> True\n",
      "   maxpooling_1 --> True\n",
      "   first_1x1_conv --> True\n",
      "   second_1x1_conv --> True\n",
      "   prototype --> True\n",
      "   final_weights --> False\n",
      "learning rate = 0.01\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 24s 104ms/step - loss: 0.2914 - sparse_categorical_accuracy: 0.9424 - cluster_cost: 0.0091 - separation_cost: 0.0073 - l1_weights_cost: 0.1289 - val_loss: 0.3041 - val_sparse_categorical_accuracy: 0.9478 - val_cluster_cost: 0.0082 - val_separation_cost: 0.0070 - val_l1_weights_cost: 0.1289\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 22s 98ms/step - loss: 0.2876 - sparse_categorical_accuracy: 0.9489 - cluster_cost: 0.0093 - separation_cost: 0.0073 - l1_weights_cost: 0.1289 - val_loss: 0.2228 - val_sparse_categorical_accuracy: 0.9756 - val_cluster_cost: 0.0112 - val_separation_cost: 0.0061 - val_l1_weights_cost: 0.1289\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 22s 96ms/step - loss: 0.2472 - sparse_categorical_accuracy: 0.9619 - cluster_cost: 0.0077 - separation_cost: 0.0048 - l1_weights_cost: 0.1289 - val_loss: 0.2121 - val_sparse_categorical_accuracy: 0.9794 - val_cluster_cost: 0.0074 - val_separation_cost: 0.0043 - val_l1_weights_cost: 0.1289\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 22s 98ms/step - loss: 0.2488 - sparse_categorical_accuracy: 0.9658 - cluster_cost: 0.0074 - separation_cost: 0.0070 - l1_weights_cost: 0.1289 - val_loss: 0.2157 - val_sparse_categorical_accuracy: 0.9783 - val_cluster_cost: 0.0045 - val_separation_cost: 0.0059 - val_l1_weights_cost: 0.1289\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 22s 99ms/step - loss: 0.2276 - sparse_categorical_accuracy: 0.9668 - cluster_cost: 0.0062 - separation_cost: 0.0057 - l1_weights_cost: 0.1289 - val_loss: 0.2296 - val_sparse_categorical_accuracy: 0.9700 - val_cluster_cost: 0.0065 - val_separation_cost: 0.0062 - val_l1_weights_cost: 0.1289\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 22s 98ms/step - loss: 0.2206 - sparse_categorical_accuracy: 0.9712 - cluster_cost: 0.0061 - separation_cost: 0.0058 - l1_weights_cost: 0.1289 - val_loss: 0.1963 - val_sparse_categorical_accuracy: 0.9761 - val_cluster_cost: 0.0072 - val_separation_cost: 0.0058 - val_l1_weights_cost: 0.1289\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 22s 99ms/step - loss: 0.2661 - sparse_categorical_accuracy: 0.9601 - cluster_cost: 0.0071 - separation_cost: 0.0101 - l1_weights_cost: 0.1289 - val_loss: 0.2306 - val_sparse_categorical_accuracy: 0.9767 - val_cluster_cost: 0.0057 - val_separation_cost: 0.0058 - val_l1_weights_cost: 0.1289\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 23s 101ms/step - loss: 0.2272 - sparse_categorical_accuracy: 0.9708 - cluster_cost: 0.0052 - separation_cost: 0.0072 - l1_weights_cost: 0.1289 - val_loss: 0.2137 - val_sparse_categorical_accuracy: 0.9739 - val_cluster_cost: 0.0064 - val_separation_cost: 0.0080 - val_l1_weights_cost: 0.1289\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 23s 101ms/step - loss: 0.2293 - sparse_categorical_accuracy: 0.9681 - cluster_cost: 0.0060 - separation_cost: 0.0071 - l1_weights_cost: 0.1289 - val_loss: 0.2070 - val_sparse_categorical_accuracy: 0.9717 - val_cluster_cost: 0.0051 - val_separation_cost: 0.0078 - val_l1_weights_cost: 0.1289\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 23s 101ms/step - loss: 0.2176 - sparse_categorical_accuracy: 0.9722 - cluster_cost: 0.0057 - separation_cost: 0.0066 - l1_weights_cost: 0.1289 - val_loss: 0.1798 - val_sparse_categorical_accuracy: 0.9861 - val_cluster_cost: 0.0057 - val_separation_cost: 0.0064 - val_l1_weights_cost: 0.1289\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/quadrants/model_quadrants_stage4\n",
      "INFO:tensorflow:Assets written to: ./saved_models/quadrants/model_quadrants_stage4/assets\n",
      "--------------------\n",
      "TRAINING STAGE = 5\n",
      "--------------------\n",
      "Running Prototype Push\n",
      "8/8 [==============================] - 5s 585ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -1.6537923\n",
      "    np.max(model.layers[-3].get_weights()[1]): 6.2321444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing push of prototypes.\n",
      "Push complete.\n",
      "\n",
      "   conv_0 --> False\n",
      "   maxpooling_0 --> False\n",
      "   conv_1 --> False\n",
      "   maxpooling_1 --> False\n",
      "   first_1x1_conv --> False\n",
      "   second_1x1_conv --> False\n",
      "   prototype --> False\n",
      "   final_weights --> True\n",
      "learning rate = 0.01\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 8s 33ms/step - loss: 1.1211 - sparse_categorical_accuracy: 0.9437 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.2116 - val_loss: 1.0232 - val_sparse_categorical_accuracy: 0.9694 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.3242\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 7s 32ms/step - loss: 1.0915 - sparse_categorical_accuracy: 0.9458 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.2018 - val_loss: 0.5690 - val_sparse_categorical_accuracy: 0.9767 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1677\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 7s 31ms/step - loss: 0.7838 - sparse_categorical_accuracy: 0.9532 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1578 - val_loss: 0.4157 - val_sparse_categorical_accuracy: 0.9594 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0729\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 7s 30ms/step - loss: 1.0097 - sparse_categorical_accuracy: 0.9435 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1788 - val_loss: 1.3417 - val_sparse_categorical_accuracy: 0.9467 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.3322\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 7s 30ms/step - loss: 1.0099 - sparse_categorical_accuracy: 0.9486 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.2370 - val_loss: 0.7861 - val_sparse_categorical_accuracy: 0.9511 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1851\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 7s 31ms/step - loss: 0.9667 - sparse_categorical_accuracy: 0.9471 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.2059 - val_loss: 0.7367 - val_sparse_categorical_accuracy: 0.9606 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1343\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 7s 30ms/step - loss: 0.8552 - sparse_categorical_accuracy: 0.9467 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1733 - val_loss: 0.7707 - val_sparse_categorical_accuracy: 0.9500 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1502\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 7s 31ms/step - loss: 0.9224 - sparse_categorical_accuracy: 0.9494 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1652 - val_loss: 1.0613 - val_sparse_categorical_accuracy: 0.9250 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.2649\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 7s 30ms/step - loss: 1.1964 - sparse_categorical_accuracy: 0.9451 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.2039 - val_loss: 0.9301 - val_sparse_categorical_accuracy: 0.9578 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.2039\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 7s 31ms/step - loss: 0.9970 - sparse_categorical_accuracy: 0.9528 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.1852 - val_loss: 0.4543 - val_sparse_categorical_accuracy: 0.9767 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1617\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/quadrants/model_quadrants_stage5\n",
      "INFO:tensorflow:Assets written to: ./saved_models/quadrants/model_quadrants_stage5/assets\n"
     ]
    }
   ],
   "source": [
    "imp.reload(push_prototypes)\n",
    "NEPOCHS    = settings['nepochs']\n",
    "STAGE_LIST = (0,1,2,3,4,5)#range(len(NEPOCHS))#(1,2,3,4,5)#range(len(NEPOCHS))\n",
    "\n",
    "for stage in STAGE_LIST:\n",
    "    \n",
    "    print('--------------------')\n",
    "    print('TRAINING STAGE = ' + str(stage))\n",
    "    print('--------------------')\n",
    "\n",
    "    # load previously trained stage, unless it is the 0th stage\n",
    "    if(stage != 0):\n",
    "        tf.keras.backend.clear_session()\n",
    "        model_filename = model_dir + 'model_' + EXP_NAME + '_stage' + str(stage-1)\n",
    "#         model = common_functions.load_model(model_filename)\n",
    "        model.load_weights(model_filename)\n",
    "        \n",
    "    # learn layers (during even numbered stages)\n",
    "    if(stage % 2 == 0):\n",
    "        # train prototypes layers (and possibly CNN layers)\n",
    "        if(settings['pretrain']==False and settings['train_cnn_in_stage'] == True):\n",
    "            model = network.set_trainable_layers(model, [True,True,True,False])            \n",
    "        elif(settings['train_cnn_in_stage'] == False or stage==0):\n",
    "            model = network.set_trainable_layers(model, [False,True,True,False])\n",
    "        elif(settings['train_cnn_in_stage'] == True):\n",
    "            model = network.set_trainable_layers(model, [True,True,True,False])            \n",
    "        elif(stage >= settings['train_cnn_in_stage']):\n",
    "            model = network.set_trainable_layers(model, [True,True,True,False])            \n",
    "        else:\n",
    "            model = network.set_trainable_layers(model, [False,True,True,False])\n",
    "    else:\n",
    "        #.......................................................\n",
    "        # push the prototypes\n",
    "        #.......................................................        \n",
    "        model, push_info = push_prototypes.push(model, \n",
    "                                                [X_train,prototypes_of_correct_class_train], \n",
    "                                                prototypes_of_correct_class_train, \n",
    "                                                perform_push=True,\n",
    "                                                batch_size=BATCH_SIZE_PREDICT,\n",
    "                                                verbose=False,\n",
    "                                               )        \n",
    "        print('Push complete.\\n')            \n",
    "\n",
    "        # train weights layer only\n",
    "        model = network.set_trainable_layers(model, [False,False,False,True])        \n",
    "\n",
    "    #.......................................................\n",
    "    # compile the model\n",
    "    #.......................................................\n",
    "    if(stage>=settings['cut_lr_stage']):\n",
    "        lr_factor = 10.**(np.floor((stage-settings['cut_lr_stage']+2)/2))\n",
    "    else:\n",
    "        lr_factor = 1.\n",
    "    if(LR_INIT/lr_factor<settings['min_lr']):\n",
    "        lr_factor = LR_INIT/settings['min_lr']\n",
    "    print('learning rate = ' + str(np.asarray(LR_INIT/lr_factor,dtype='float32')))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=np.asarray(LR_INIT/lr_factor,dtype='float32'), \n",
    "        ),\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics = metrics_list,\n",
    "    )\n",
    "#     model.summary()\n",
    "    ic(np.min(model.layers[-3].get_weights()[1]),np.max(model.layers[-3].get_weights()[1]))\n",
    "\n",
    "    #.......................................................\n",
    "    # train the model\n",
    "    #.......................................................\n",
    "    print('Training the model...')    \n",
    "    \n",
    "    tf.random.set_seed(RANDOM_SEED)   \n",
    "    np.random.seed(RANDOM_SEED)    \n",
    "    history = model.fit(\n",
    "        [X_train,prototypes_of_correct_class_train],\n",
    "        y_train,\n",
    "        validation_data=([[X_val,prototypes_of_correct_class_val]], [y_val]),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=NEPOCHS[stage],\n",
    "        shuffle=True,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list\n",
    "    )\n",
    "    print('Training complete.\\n')            \n",
    "        \n",
    "\n",
    "    # save the model at this training stage\n",
    "    model_filename = model_dir + 'model_' + EXP_NAME + '_stage' + str(stage)\n",
    "    common_functions.save_model(model, model_filename) \n",
    "    \n",
    "    #.......................................................\n",
    "    # plot results\n",
    "    #.......................................................  \n",
    "    try:\n",
    "        # plot loss history of the model\n",
    "        plots.plot_loss_history(history)\n",
    "        plt.savefig(model_diagnostics_dir + EXP_NAME + '_loss_history_stage' + str(stage) + '.png', dpi=dpiFig)    \n",
    "        plt.close()\n",
    "\n",
    "        # plot the weights\n",
    "        plots.plot_weights(model, PROTOTYPES_PER_CLASS)    \n",
    "        plt.savefig(model_diagnostics_dir + EXP_NAME + '_weights_stage' + str(stage) + '.png', dpi=dpiFig)\n",
    "        plt.close()\n",
    "    except:\n",
    "        print('not making plots...')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b663b0-f667-4172-a71a-7344b14b9590",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
