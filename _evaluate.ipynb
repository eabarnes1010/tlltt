{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f6a48b-bab3-4333-abf3-07711e94b616",
   "metadata": {},
   "source": [
    "# This Looks Like That There\n",
    "code to evaluate models without figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bf3dd4-d4af-4c8c-89f6-67097628c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import imp \n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "from icecream import ic          # pip install icecream\n",
    "import scipy.io as sio\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import cmasher as cmr            # pip install cmasher\n",
    "\n",
    "import cartopy as ct\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import network\n",
    "import experiment_settings \n",
    "import data_functions\n",
    "import push_prototypes\n",
    "import plots\n",
    "import common_functions\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings( \"ignore\", module = \"cartopy\\..*\" )\n",
    "warnings.filterwarnings( \"ignore\", module = \"matplotlib\\..*\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e0dba3-9a8a-4d45-b00b-7aaface5fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Elizabeth A. Barnes and Randal J Barnes\"\n",
    "__version__ = \"23 November 2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18825d5a-a951-4a29-8dbd-1b1956974b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.facecolor'] = 'white'\n",
    "mpl.rcParams['figure.dpi']= 150\n",
    "dpiFig = 400."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce58c40-dd37-43ea-9ad3-6d6b56b7d166",
   "metadata": {},
   "source": [
    "## Print the detailed system info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e923341-795f-428a-b5bf-d8cafdce1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"python version = {sys.version}\")\n",
    "print(f\"numpy version = {np.__version__}\")\n",
    "print(f\"tensorflow version = {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9a01c1-9474-4757-8ed3-b4851b636af4",
   "metadata": {},
   "source": [
    "## Define experiment settings and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ecf9b-652f-4588-87e9-88e0915b37ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = 'quadrants'\n",
    "\n",
    "imp.reload(experiment_settings)\n",
    "settings = experiment_settings.get_settings(EXP_NAME)\n",
    "\n",
    "imp.reload(common_functions)\n",
    "model_dir, model_diagnostics_dir, vizualization_dir = common_functions.get_exp_directories(EXP_NAME)\n",
    "vizualization_dir = '/Users/eabarnes/GoogleDrive/WORK/RESEARCH/2021/thisLooksLikeThat/TLLT-clean/figures/final/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c333c24-ae7d-43d3-bc87-09fc8e7d8e89",
   "metadata": {},
   "source": [
    "## Define the network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3005d411-649b-484a-8c3e-fc23500e11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED          = settings['random_seed']\n",
    "BATCH_SIZE_PREDICT   = settings['batch_size_predict']\n",
    "BATCH_SIZE           = settings['batch_size']\n",
    "NLAYERS              = settings['nlayers']\n",
    "NFILTERS             = settings['nfilters']   \n",
    "DOUBLE_CONV          = settings['double_conv']   \n",
    "assert(len(NFILTERS)==NLAYERS)\n",
    "\n",
    "NCLASSES             = settings['nclasses']\n",
    "PROTOTYPES_PER_CLASS = settings['prototypes_per_class']\n",
    "NPROTOTYPES          = np.sum(PROTOTYPES_PER_CLASS)\n",
    "\n",
    "NEPOCHS              = settings['nepochs']\n",
    "LR_INIT              = settings['lr']\n",
    "LR_EPOCH_BOUND       = 10000\n",
    "PATIENCE             = 100\n",
    "\n",
    "STAGE                = settings['analyze_stage']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ab2e28-c92f-4c2d-a5d2-96dcfd9625a3",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb857807-8efc-485b-8be6-29751f6a4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521a7140-1796-429f-ad34-1ff25ecca436",
   "metadata": {},
   "source": [
    "## Get and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e0d1f-f892-46f8-a957-c4cf046ab215",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(data_functions)\n",
    "DATA_NAME = settings['data_name']\n",
    "DATA_DIR = settings['data_dir']\n",
    "\n",
    "if(EXP_NAME[:3]=='mjo'):\n",
    "\n",
    "    labels, data, lat, lon, time = data_functions.load_mjo_data(DATA_DIR)\n",
    "    X_train, y_train, time_train, X_val, y_val, time_val, X_test, y_test, time_test = data_functions.get_and_process_mjo_data(labels,\n",
    "                                                                                         data,\n",
    "                                                                                         time,\n",
    "                                                                                         rng, \n",
    "                                                                                         colored=settings['colored'],\n",
    "                                                                                         standardize=settings['standardize'],\n",
    "                                                                                         shuffle=settings['shuffle'],\n",
    "                                                                                        )        \n",
    "elif(EXP_NAME[:9]=='quadrants'):\n",
    "    filename = DATA_DIR + DATA_NAME + '.mat'\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, lat, lon = data_functions.get_and_process_data(filename, \n",
    "                                                                                        rng, \n",
    "                                                                                        colored=settings['colored'],\n",
    "                                                                                        standardize=settings['standardize'],\n",
    "                                                                                        shuffle=settings['shuffle'],\n",
    "                                                                                        )      \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa63e6-adc0-40b0-92a1-16dd4cc806f6",
   "metadata": {},
   "source": [
    "## Get the model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff03a015-a4a4-4b37-b228-40c0bd100566",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = model_dir + 'model_' + EXP_NAME + '_stage' + str(STAGE)\n",
    "model = common_functions.load_model(model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46e0ad3-1993-4598-b181-4f1320938eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_class_mask = network.createClassIdentity(PROTOTYPES_PER_CLASS)\n",
    "\n",
    "prototypes_of_correct_class_train = np.zeros((len(y_train),NPROTOTYPES))\n",
    "for i in range(0,prototypes_of_correct_class_train.shape[0]):\n",
    "    prototypes_of_correct_class_train[i,:] = proto_class_mask[:,int(y_train[i])]\n",
    "    \n",
    "prototypes_of_correct_class_val   = np.zeros((len(y_val),NPROTOTYPES))    \n",
    "for i in range(0,prototypes_of_correct_class_val.shape[0]):\n",
    "    prototypes_of_correct_class_val[i,:] = proto_class_mask[:,int(y_val[i])]\n",
    "\n",
    "prototypes_of_correct_class_test   = np.zeros((len(y_test),NPROTOTYPES))    \n",
    "for i in range(0,prototypes_of_correct_class_test.shape[0]):\n",
    "    prototypes_of_correct_class_test[i,:] = proto_class_mask[:,int(y_test[i])]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b1cb0f-1fde-4d7a-afaa-1b3d982fa1b1",
   "metadata": {},
   "source": [
    "## Validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e76986-a0f6-44ce-8bbc-578308ddabc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_val  = [[X_val,prototypes_of_correct_class_val]]\n",
    "\n",
    "print('......ProtoLNet Metrics......')\n",
    "print('running model.predict()')\n",
    "y_predict_val = model.predict(input_val, batch_size=BATCH_SIZE_PREDICT, verbose=1)\n",
    "print('model.predict() complete.')\n",
    "\n",
    "model.evaluate(input_val,y_val,batch_size=BATCH_SIZE_PREDICT, verbose=1)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b29669c-6fb6-4bc8-b7ff-11b8a5bd684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracies by class: ')\n",
    "\n",
    "for c in np.arange(0,NCLASSES):\n",
    "    i = np.where(y_val==c)[0]\n",
    "    j = np.where(y_val[i]==np.argmax(y_predict_val[i],axis=1))[0]\n",
    "    acc = np.round(len(j)/len(i),3)\n",
    "    \n",
    "    print('   phase ' + str(c) + ' = ' + str(acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4694c4-c1ba-46f0-8bef-13be22231d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(settings['pretrain_exp'] is None):\n",
    "    PRETRAINED_MODEL = model_dir + 'pretrained_model_' + EXP_NAME \n",
    "else:\n",
    "    PRETRAINED_MODEL = './saved_models/' + settings['pretrain_exp'] \n",
    "\n",
    "print('......Base CNN Metrics......')\n",
    "print('loading pretrained convolutional layers from ' + PRETRAINED_MODEL)\n",
    "pretrained_model = tf.keras.models.load_model(PRETRAINED_MODEL)\n",
    "y_predict_val_cnnbase = pretrained_model.predict(X_val, batch_size=BATCH_SIZE_PREDICT, verbose=1)\n",
    "print('model.predict() complete.')\n",
    "pretrained_model.evaluate(X_val,y_val,batch_size=BATCH_SIZE_PREDICT, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0cfbad-48ef-49ad-b41f-d39b2b4a892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94be8cb6-6069-4b2e-959d-1c14ef7bebf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
